{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54cec73d094547bbacd4815d4c00df42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d316adf9ebe44588911978aeadf99da4",
              "IPY_MODEL_498b3e9c437e4dde8b75e6d85d01a545"
            ],
            "layout": "IPY_MODEL_e50f4dcd25eb434391e9ede8fc0c413d"
          }
        },
        "e50f4dcd25eb434391e9ede8fc0c413d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d316adf9ebe44588911978aeadf99da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8092f8184aea440692882c11a286f2ae",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3c09d1c63c47b68a7b7f26902b84ce",
            "value": 760
          }
        },
        "498b3e9c437e4dde8b75e6d85d01a545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b841ecf971a4cb6879401e1d0b54865",
            "placeholder": "​",
            "style": "IPY_MODEL_58a70ab48c7d424eb7f78cadcc159e62",
            "value": " 760/760 [17:30&lt;00:00, 1.38s/B]"
          }
        },
        "ea3c09d1c63c47b68a7b7f26902b84ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "8092f8184aea440692882c11a286f2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a70ab48c7d424eb7f78cadcc159e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b841ecf971a4cb6879401e1d0b54865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz5sIaGaOMIB"
      },
      "source": [
        "# Text Classification with Albert-Persian\n",
        "> Text Classification with Transformers-LMs in TF 2.X & PyTorch \n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- image: images/albert.png\n",
        "- author: Sajjad Ayoubi\n",
        "- categories: [nlp, jupyter]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQtnpj0uChfX"
      },
      "source": [
        "## What's ALBERT-Persian?\n",
        "\n",
        "A Lite BERT for Self-supervised Learning of Language Representations for the Persian Language<br>\n",
        "- thanks [Mehrdad Farahani](https://github.com/m3hrdadfi) & [Hoshvare](https://hooshvare.com/) for sharing this\n",
        "[albert-persian repo](https://github.com/m3hrdadfi/albert-persian)\n",
        "\n",
        "ALBERT-Persian trained on a massive amount of public corpora (Persian Wikidumps, MirasText) and six other manually crawled text data from a various type of websites (BigBang Page scientific, Chetor lifestyle, Eligasht itinerary, Digikala, Ted Talks general conversational, Books novels, storybooks, short stories from old to the contemporary era)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNoo60hYvvEr"
      },
      "source": [
        "# Dataset (DigiMag)\n",
        " - For this notebook, I'm going to use DigiMag dataset for text classification\n",
        "    - train len: **6865**  , valid len:**767** , test len: **852**\n",
        "    - it has **7** types for Magazines (7 classes)\n",
        "    - thanks [Hooshvare](https://hooshvare.com/) for sharing this\n",
        "\n",
        "- this is an example of how to use (You can use whatever dataset you have)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X_hLyuxROac"
      },
      "source": [
        "- the training was on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRCmt0dyAhnb",
        "outputId": "89850373-fa0e-4b2f-f278-82e1dab389e6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Feb 18 05:45:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MVyv3Z1Atj3",
        "outputId": "77e3df15-2e02-4a67-fac9-e7f7c3cb0893"
      },
      "source": [
        "# Install required packages for model\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q transformers\n",
        "!pip install -q tokenizers\n",
        "# for text processing\n",
        "!pip -q install hazm\n",
        "!pip -q install clean-text[gpl]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.2MB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 38.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 317kB 5.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 17.9MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 6.9MB/s \n",
            "\u001b[?25h  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkl5fWZqEYeW"
      },
      "source": [
        "# Import required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm \n",
        "\n",
        "from hazm import Normalizer\n",
        "from hazm import WordTokenizer\n",
        "from cleantext import clean\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C--S3wCZBxwP"
      },
      "source": [
        "## Load\n",
        "  - the dataset is [here](https://bit.ly/3ca4bm8) on Drive (open it with VPN)\n",
        "  - add it on your drive and use it like the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saX146rRvg-A",
        "outputId": "277d9a62-d849-40fb-ce96-ee92b0bcbe0f"
      },
      "source": [
        "# mount the google drive and change current dir\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94NMzgX7szSu",
        "outputId": "1cfeee26-41c5-4f63-b7d2-196d18cf6564"
      },
      "source": [
        "# unzip the dataset in your drive\n",
        "!unzip digimag.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  digimag.zip\n",
            "   creating: digimag/\n",
            "  inflating: digimag/dev.csv         \n",
            "  inflating: digimag/train.csv       \n",
            "  inflating: digimag/test.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT6NpaNYEKih"
      },
      "source": [
        "-  load train, test, and valid with Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tqg1XDzMuzRy",
        "outputId": "0fd8cfe4-63f2-4101-f94b-377148a890d1"
      },
      "source": [
        "train_df = pd.read_csv('digimag/train.csv', delimiter=\"\t\", index_col=False)\n",
        "eval_df = pd.read_csv('digimag/dev.csv', delimiter=\"\t\", index_col=False)\n",
        "test_df = pd.read_csv('digimag/test.csv', delimiter=\"\t\", index_col=False)\n",
        "\n",
        "# drop the label columns\n",
        "train_df.drop(columns=['Unnamed: 0', 'label'], inplace=True)\n",
        "eval_df.drop(columns=['Unnamed: 0', 'label'], inplace=True)\n",
        "test_df.drop(columns=['Unnamed: 0', 'label'], inplace=True)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>نمایش تبلیغ در لاک‌اسکرین تعدادی از گوشی‌های ه...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>شکست Justice League در باکس آفیس پس از بازخورد...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>کلاسیک بینی؛ همه چیز در یک شب اتفاق افتاد فیلم...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اپل دوباره سراغ رنده رفته چراکه آپگرید کردن سط...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>بررسی جزء به جزء بهترین بخش Ori and the Blind ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  label_id\n",
              "0  نمایش تبلیغ در لاک‌اسکرین تعدادی از گوشی‌های ه...         3\n",
              "1  شکست Justice League در باکس آفیس پس از بازخورد...         5\n",
              "2  کلاسیک بینی؛ همه چیز در یک شب اتفاق افتاد فیلم...         5\n",
              "3  اپل دوباره سراغ رنده رفته چراکه آپگرید کردن سط...         3\n",
              "4  بررسی جزء به جزء بهترین بخش Ori and the Blind ...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjoOLYuSEbkL"
      },
      "source": [
        "## Normalization (Preprocessing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQv3zFm0F2Xc"
      },
      "source": [
        "Our cleaning method includes these steps:\n",
        "\n",
        "- fixing unicodes\n",
        "- removing specials like a phone number, email, url, new lines, ...\n",
        "- cleaning HTMLs\n",
        "- normalizer\n",
        "- tokenize and detokenize (for adding space)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca2tk50DE07M"
      },
      "source": [
        "# for more details see hazm doc\n",
        "tokenizer = WordTokenizer(join_verb_parts=False, replace_hashtags=False, replace_IDs=False)\n",
        "normalizer = Normalizer(remove_extra_spaces=True, persian_numbers=False, persian_style=True,\n",
        "                        punctuation_spacing=False, remove_diacritics=True,\n",
        "                        affix_spacing=False, token_based=True)\n",
        "\n",
        "def cleaning(text):\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=True,\n",
        "        no_digits=True,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=True,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_currency_symbol=\"\")\n",
        "    \n",
        "    text = re.sub(r'([ا-ی])\\1{2,}', r'\\1', text) # bbb+ -> b at least 2 char\n",
        "    return text.strip()\n",
        "\n",
        "def text_preprocessor(t, tokenize=False):\n",
        "  tokens = tokenizer.tokenize(cleaning(normalizer.normalize(t)))\n",
        "  return tokens if tokenize else ' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y6TRc3uMz5X",
        "outputId": "2a8ca479-8a45-4301-da3a-5a16de3bf91c"
      },
      "source": [
        "# clean test set and valid set\n",
        "test_df['cleaned'] = test_df.content.apply(text_preprocessor)\n",
        "print('test cleaned')\n",
        "eval_df['cleaned'] = eval_df.content.apply(text_preprocessor)\n",
        "print('valid cleaned')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test cleaned\n",
            "valid cleaned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "tSdjVnfkF0he",
        "outputId": "4f082490-7ab0-4124-8798-95fb21208b36"
      },
      "source": [
        "# clean and tokenize train set\n",
        "train_df['cleaned'] = train_df.content.apply(text_preprocessor)\n",
        "print('train cleaned')\n",
        "train_df['tokens'] = train_df.content.apply(text_preprocessor, tokenize=True)\n",
        "train_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train cleaned\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label_id</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>نمایش تبلیغ در لاک‌اسکرین تعدادی از گوشی‌های ه...</td>\n",
              "      <td>3</td>\n",
              "      <td>نمایش تبلیغ در لاک اسکرین تعدادی از گوشی های ه...</td>\n",
              "      <td>[نمایش, تبلیغ, در, لاک, اسکرین, تعدادی, از, گو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>شکست Justice League در باکس آفیس پس از بازخورد...</td>\n",
              "      <td>5</td>\n",
              "      <td>شکست justice league در باکس آفیس پس از بازخورد...</td>\n",
              "      <td>[شکست, justice, league, در, باکس, آفیس, پس, از...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>کلاسیک بینی؛ همه چیز در یک شب اتفاق افتاد فیلم...</td>\n",
              "      <td>5</td>\n",
              "      <td>کلاسیک بینی همه چیز در یک شب اتفاق افتاد فیلم ...</td>\n",
              "      <td>[کلاسیک, بینی, همه, چیز, در, یک, شب, اتفاق, اف...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...                                             tokens\n",
              "0  نمایش تبلیغ در لاک‌اسکرین تعدادی از گوشی‌های ه...  ...  [نمایش, تبلیغ, در, لاک, اسکرین, تعدادی, از, گو...\n",
              "1  شکست Justice League در باکس آفیس پس از بازخورد...  ...  [شکست, justice, league, در, باکس, آفیس, پس, از...\n",
              "2  کلاسیک بینی؛ همه چیز در یک شب اتفاق افتاد فیلم...  ...  [کلاسیک, بینی, همه, چیز, در, یک, شب, اتفاق, اف...\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUbz0N7nH932"
      },
      "source": [
        "### display the frequent words in the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "vLyrV3jrGXyP",
        "outputId": "d54e3933-dd7d-4746-9096-7b2bfeee526f"
      },
      "source": [
        "word_list = []\n",
        "for s in train_df.tokens:\n",
        "    for w in s:\n",
        "        word_list.append(w)\n",
        "\n",
        "words = pd.DataFrame(word_list, columns=['words'])\n",
        "top = words.groupby(['words']).size().sort_values(ascending=False)\n",
        "print('number of words', len(top.index))\n",
        "plt.figure(figsize = (8,12))\n",
        "sns.barplot(x=top.values[:30], y=top.index[:30]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words 80154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAKrCAYAAABslI7UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZQldX338feHZdiGYWZYBgV0QBAVZIltDKI5Y+KCiEEUCUbzgMIziiiYEJ8YzZMYk2hiohESjE5CFIHHqCwxLggqIaKHaFowKkTZXMDIvgyjwrB8nz9uDTbtNDPDTN+6dev9OqcP91bVvfdTp5rpT//q11WpKiRJUn9t1HYASZLULsuAJEk9ZxmQJKnnLAOSJPWcZUCSpJ7bpO0Abdluu+1q8eLFbceQJGlovv71r99aVdtPX97bMrB48WImJyfbjiFJ0tAk+cHqlnuaQJKknuvtyMD9t9zOLX9/ZtsxJEn6Bdsf96qhfp4jA5Ik9ZxlQJKknrMMSJLUc5YBSZJ6zjIgSVLPWQYkSeo5y4AkST3XqzKQZGmSySSTt61Y3nYcSZJGQq/KQFUtq6qJqprYdu68tuNIkjQSxq4MJPmrJN9PcmLbWSRJ6oKxKgNJFgKvAfYF3pBkq5YjSZI08saqDFTV7cB5wJXALsD8dhNJkjT6xqoMAFTVscAzgJ8CP245jiRJI2+sykCSjZLsD3waOKWqHmw7kyRJo25sbmGc5GXAXwDXAydX1YdajiRJUieMTRmoqnOAc9rOIUlS14xNGVhXm2y/kO2Pe1XbMSRJat1YzRmQJEnrzjIgSVLPWQYkSeq53s4ZuP+Wm7n5A6e0HUOSNCQ7vO6EtiOMLEcGJEnqOcuAJEk9ZxmQJKnnLAOSJPWcZUCSpJ6zDEiS1HOWAUmSes4yIElSz3W6DCRZnOT167D90iSTSSZvW7FiNqNJktQZnS4DVfV9YCLJsauWJZmTZPMZtl9WVRNVNbHt3LnDiilJ0kjrdBlovBN47ZTnvwyc0VIWSZI6p7NlIMmq+yrsA0wd878V2Hb4iSRJ6qYu36joJUn+BvgxcOyU5UcCk+1EkiSpezpbBqrqbOBsgAzsBrweOBQ4sM1skiR1SWfLwDRfBh4AzgV+qarubjmPJEmdMRZloKocCZAk6VHq7ARCSZK0YYzFyMCjscn2O7DD605oO4YkSa1zZECSpJ6zDEiS1HOWAUmSeq63cwbuu/l6/ufU3207hiRpPTz2+Pe2HWEsODIgSVLPWQYkSeo5y4AkST1nGZAkqecsA5Ik9ZxlQJKknrMMSJLUc5YBSZJ6rvNlIMmTk7woyQlJrk5ySpKtZth2aZLJJJO3rfjZsKNKkjSSOlEGkjwnyUdmWL0fcCjw+8AE8D3g/avbsKqWVdVEVU1sO3eL2QkrSVLHdKIMAJsBuyXZftWCJIuSHA28EzgDeAC4H7gI2LuNkJIkdVFX7k1wAbA/8JUkWwIPArcBFwOHVNUVSZYBVwG3ACe1FVSSpK7pRBmoqgLe1XzNtM2fAX82tFCSJI2JrpwmeJgkp7edQZKkcdHJMlBVR7WdQZKkcdHJMiBJkjYcy4AkST3XiQmEs2HTHXbhsce/t+0YkiS1zpEBSZJ6zjIgSVLPWQYkSeq53s4ZuOfma/jOqYe2HUOSOuVJx3+y7QiaBY4MSJLUc5YBSZJ6zjIgSVLPWQYkSeo5y4AkST3X+TKQ5Ia2M0iS1GWdLwOSJGn9WAYkSeq5sSsDSbZMctoM65YmmUwyeceKlcOOJknSSBq7MlBVP62qY2ZYt6yqJqpqYsHcOcOOJknSSBq7MgCQ5GtJtmo7hyRJXTCWZQC4H9iu7RCSJHXB2JWBJI8DdgX8k0NJktZC58tAVe0MkGTrJEcC/w78QVU90G4ySZK6YSxuYZzkJOAo4BLgJVX1Xy1HkiSpM8aiDFTVe4D3tJ1DkqQuGosy8GhsvsPuPOn4T7YdQ5Kk1nV+zoAkSVo/lgFJknrOMiBJUs9ZBiRJ6rneTiD8yS3XcOmyQ9qOIUmtOWDpp9uOoBHhyIAkST1nGZAkqecsA5Ik9ZxlQJKknrMMSJLUc5YBSZJ6zjIgSVLP9aoMJFmaZDLJ5B0rVrYdR5KkkdC5MpDkmCTXJjkzyRZTls9Pcm6S65p1c6a/tqqWVdVEVU0smPsLqyVJ6qVOlYEkmwEnA08HlgMvmrJ6CTAf2Au4ANh+2PkkSeqizpSBJAuBzwPnAF8H9gb+M8kbm03OBy4HLgO2rqoftRJUkqSO6UwZAJ4HfK+qjqqqXavqV4FFzXKq6t6qOonBCMGftBdTkqRu6dKNirYAatqyK4HFSd4K3AjsCRwEvGXI2SRJ6qwujQz8gqpaARwIXA/MAS4EDqiq01oNJklSh3RmZKCqPgx8eDXL7wbOGHYeSZLGRadHBiRJ0vrrzMjAhrbV9rtzwNJPtx1DkqTWOTIgSVLPWQYkSeo5y4AkST3X2zkDy2+9mgtOO7jtGJK01l5wzGfbjqAx5ciAJEk9ZxmQJKnnLAOSJPWcZUCSpJ6zDEiS1HOdLwNJ5iZ5XZKL2s4iSVIXdbYMJNkiycnAZcBOwG+3HEmSpE7q8nUGDgP2AvauqpVth5Ekqas6OzIAXMhgRGDvtX1BkqVJJpNM3nW3/UGSJOhQGcjA1queV9WtwCuAf06yKMlmSb6Q5LIkR6zuPapqWVVNVNXENlvPGVZ0SZJGWmfKAPA84OSpC6rqG8CHgdcCzwduBJ4LHJfk14YdUJKkLupSGbgfeGqSPZpRgi2SHAocCVzLYP7DPVV1O3A5g/kEkiRpDTozgbCqLkpyGvBRYBHwM+BS4KSq+nySbYDfTXID8DXgT9tLK0lSd3SmDABU1QeAD8yw7i7g2cNNJElS93XpNIEkSZoFlgFJknrOMiBJUs91as7AhjRvuz14wTGfbTuGJEmtc2RAkqSeswxIktRzlgFJknqut3MG7rj1as7+0EFtx5DUAYe/+nNtR5BmlSMDkiT1nGVAkqSeswxIktRzlgFJknrOMiBJUs+NbBlobkUsSZJm2ciWAUmSNByWAUmSeq5XZSDJ0iSTSSaXr1jZdhxJkkZCp8pAkn2SXJrkqiS/P23dLkkWNY9/e3Wvr6plVTVRVRPz5s4ZRmRJkkZep8oA8BrgYmAf4N4MbJpkblVdX1U3NdsdmWSitZSSJHXIyJeBJE9M8hvN0/cAuwOXApdVVQHHAm+e9rLvAE8YXkpJkrpr5MsA8BIGBYDmt/+XA+8CTmzWLwBum/aaPYGbkCRJazSydy2sqp2bhxcB/5TkZ83zfYFnMhgRALgMeFuSs6rqtiS/BewCfGmogSVJ6qiRHxmoqkngxcCDwL3AacB+VfW1Zv3ngHOAi5JcBxwMvKiqHmwpsiRJnTKyIwNTVdUPgA8+wvr3Ae8bXiJJksbHyI8MSJKk2dWJkYHZsGC7PTj81Z9rO4YkSa1zZECSpJ6zDEiS1HOWAUmSeq63cwZuve0qPnT689uOIWlIXn3UhW1HkEaWIwOSJPWcZUCSpJ6zDEiS1HOWAUmSes4yIElSz41dGUiyOMmX284hSVJXjF0ZkCRJ68YyIElSz/WqDCRZmmQyyeSKu+9rO44kSSNhrMpAknmPtL6qllXVRFVNzN1602HFkiRppI1VGQDOBbZqO4QkSV0ybmXgVmDbtkNIktQlY1MGkiwEfhW4u+0skiR1SefLQJItkrwY+DLw3qq6vKqe1XYuSZK6otO3ME7ym8AfAV8DjqmqS1uOJElS53S6DFTVx4CPtZ1DkqQu63QZWB/bbftEXn3UhW3HkCSpdZ2fMyBJktaPZUCSpJ6zDEiS1HOWAUmSeq63Ewhvvv1qTjnrBW3HkEbGCa+8oO0IklriyIAkST1nGZAkqecsA5Ik9ZxlQJKknrMMSJLUc62XgSQ3tJ1BkqQ+a70MSJKkdvWqDCRZmmQyyeSK5SvbjiNJ0kjoVRmoqmVVNVFVE3PnzWk7jiRJI6FzZSDJmUmWTFt2XJKTkhzXPN8yyeNaCShJUseMbBlIsnGS7zaP90pyyapVQCXZJcl5AFX191X1nqr6+2abJwKnDT+1JEndMzJlIMn+Sc5f9byqHgB+kOR5wNOApyTZBlgM/AiYBzxp6ghAkq2TPB94P/CZYeaXJKmrRulGRUuAL0xb9lhgGfAAgx/wVwH/UlXXACT5O+CCpiTcB/wMmAT+tKrOR5IkrVHrZaCqdm4e3gs8I8kcBrneCtxfVbtO2fz/TnvtqcCpQwkqSdKYGpnTBMBHgE2B7wBXMBgVeF6riSRJ6oHWRwZWqaoVwG+1nUOSpL4ZmTIwbDss3IMTXnlB2zEkSWrdKJ0mkCRJLbAMSJLUc5YBSZJ6rrdzBv7njqt5+8df0HYMaSS8/Qjnz0h95siAJEk9ZxmQJKnnLAOSJPWcZUCSpJ6zDEiS1HOdLANJLk6ye9s5JEkaB50sA5IkacOxDEiS1HO9KgNJliaZTDL50+Ur244jSdJIGPkykGSzJF9IclmSIx5hu/lJzk1yXZIzk8yZvk1VLauqiaqa2HLeL6yWJKmXunA54ucDNwJHAOckuXWG7ZYA84G9gMOB7YEfDSOgJEldNvIjAwwKyz1VdTtwOYMf9sBDowZvbJ6e36y/DNi6qiwCkiSthS6UgYuAPZPcACwGzpyybl/geQBVdW9VncRghOBPhpxRkqTOGvnTBFV1F/DsaYuXACSZCyxO8lYGpxL2BA4C3jLMjJIkdVkXRgZmVFUrgAOB64E5wIXAAVV1WqvBJEnqkJEfGViTqrobOKPtHJIkdVWnRwYkSdL66/zIwKP12AV78PYjLmg7hiRJrXNkQJKknrMMSJLUc5YBSZJ6rrdzBr5/59W8+ryD2o6hHvrQYZ9rO4IkPYwjA5Ik9ZxlQJKknrMMSJLUc5YBSZJ6zjIgSVLPjWUZSPLhJM9tO4ckSV0wlmVAkiStPcuAJEk916sykGRpkskkk/csX9l2HEmSRsJYXYEwyZOB3WZaX1XLgGUA2+2+TQ0rlyRJo6xzIwNJnpPkIzOs3g84dJh5JEnqus6VAWAzYLck269akGRRkqOBdwJntBVMkqQu6uJpgguA/YGvJNkSeBC4DbgYOKSqrkhyTIv5JEnqlM6Vgaoq4F3N10zbHD20QJIkdVwXTxM8TJLT284gSVKXdb4MVNVRbWeQJKnLOneaYENZPH8PPnTY59qOIUlS6zo/MiBJktaPZUCSpJ6zDEiS1HOWAUmSeq63EwivvvOHvPCTx7cdQ+vp/ENPbTuCJHWeIwOSJPWcZUCSpJ6zDEiS1HOWAUmSes4yIElSz3WyDCS5OMnubeeQJGkcdLIMSJKkDccyIElSz/WqDCRZmmQyyeTK5T9rO44kSSNhZMtAkicnedGU55snmfMI289Pcm6S65Kcubptq2pZVU1U1cSceVvMVnRJkjql1TKQ5DlJPjLD6v2AQ6c8Pxz480d4uyXAfGAv4AJg+w2RUZKkcdf2yMBmwG5JHvrBnWRRkqOBdwJnTNn2VmDbqS9OslmSNzZPzwcuBy4Dtq6qH81mcEmSxkXbZeAC4DPAV5LckOSHwOeAfYFDquqSKdseCUxOe/2+wPMAqureqjqJwQjBn8x2cEmSxkWrdy2sqgLe1Xz9giQbAU8G3gw8BTiued2SZv1cYHGStwI3AnsCBwFvme3skiSNi7ZHBh4myelTHm8MXAX8DXAJ8KyqetifAFTVCuBA4HpgDnAhcEBVnTa00JIkdVyrIwPTVdVRUx4/AKzxKoNVdTcPn1sgSZLWwUiVgWHaY/7jOP/QU9uOIUlS60bqNIEkSRo+y4AkST1nGZAkqecsA5Ik9VxvJxBefeePOfi8P2s7hh6Fzx72h21HkKSx4siAJEk9ZxmQJKnnLAOSJPWcZUCSpJ4byzKQ5OIka7yUsSRJGtMyIEmS1p5lQJKknutVGUiyNMlkksmVy3/SdhxJkkZC58tAks2SfCHJZUmOeKRtq2pZVU1U1cSceVsNK6IkSSNtHK5A+HzgRuAI4Jwkt7acR5KkTun8yACDQnNPVd0OXA7s1XIeSZI6ZRzKwEXAnkluABYDZ7YbR5Kkbun8aYKqugt49rTFS1qIIklSJ43DyIAkSVoPlgFJknrOMiBJUs91fs7Ao7XH/Mfw2cP+sO0YkiS1zpEBSZJ6zjIgSVLPWQYkSeq53s4ZuPrOm3nRuae0HUPr4DMvPaHtCJI0lhwZkCSp5ywDkiT1nGVAkqSe62QZSLJxkpcl2TTJPkl2ajuTJEld1ckyADwT2IbBLYtPBG5pN44kSd3VyTJQVZdU1T8B86vqmKpa2XYmSZK6qpNlQJIkbTiWAUmSeq5XZSDJ0iSTSSZX3rWi7TiSJI2EsSkDSbZLsrh5/PIkm0/fpqqWVdVEVU3M2WbusCNKkjSSOn854iQbA3Or6lbg1mbxEqCAs9vKJUlSV4zDyMDzgek3GfgO8IQWskiS1DnjUAYWALdNW7YncFMLWSRJ6pxOl4Gq2hn4BvDCJLsAJPl14IXAeW1mkySpKzo/Z6CqrkzyDuC8JAuBbwEvrqq7Wo4mSVIndL4MAFTVR4GPtp1DkqQu6vRpAkmStP7GYmTg0dhj/g585qUntB1DkqTWOTIgSVLPWQYkSeo5y4AkST3X2zkDV99xKy865x/bjqEpPvOyY9uOIEm95MiAJEk9ZxmQJKnnLAOSJPWcZUCSpJ6zDEiS1HOWAUmSem6dy0CSBUn2mY0wkiRp+NaqDCS5OMm85hbBlwH/kOS9sxtNkiQNw9qODGxTVcuBlwIfqapnAM+dvViPTpLHJfl8kmuTvG8165cmmUwyuXL53W1ElCRp5KxtGdgkyWOAI4BPz2Ke9fVS4CbgycBVSeZOXVlVy6pqoqom5szbupWAkiSNmrUtA+8ALgCuqar/TLIbcPXsxVp7SXZI8r+ap6cD9wKXAzdV1Yr2kkmS1A1rVQaq6hNVtU9Vvb55fl1VvWx2o621JcAEQFXdUVXHAK8G3tpmKEmSuuIRb1SU5G+Bmml9VZ2wwROtu/8A/jjJm4CfAHsBvw68pdVUkiR1xJpGBiaBrwObA7/E4NTA1cB+wJzZjbZ2quqHwHOAu4EAZwNPq6rPtBpMkqSOeMSRgao6HSDJccCzqur+5vkHgEtmP97aqaqbgdPaziFJUhet7QTCBcC8Kc/nNsskSVLHPeLIwBR/AVye5N8YDMX/KvD22Qo1DHss2I7PvOzYtmNIktS6NZaBJBsB3wWe0XwB/H5V3TibwSRJ0nCssQxU1YNJTq2q/YFPDiGTJEkaorWdM/DFJC9LkllNI0mShm5ty8BrgU8AK5Pc3Xwtn8VckiRpSNZqAmFVjd2F/K+543YOOfustmP00qcPf2XbESRJU6ztXxOQ5DcY/BUBwMVVNco3LJIkSWtprU4TJPkL4ETgyubrxCTvms1gkiRpONZ2ZOBgYL+qehAgyekM7gz4B7MVTJIkDcfaTiAEmD/l8TYbOogkSWrH2o4MvBO4LMnF/PwKhN4VUJKkMbC2IwOHAP/E4A6GZwMHVNXHZi3VFEk+nOS5w/gsSZL6aG1HBk4Dng38BvAEBvcp+FJVnTxrySRJ0lCs7XUG/i3Jl4CnA88BXgfsBVgGJEnquLX908IvAl8BfpPBTYueXlVPms1ga8jz/iTrfAvlJEuTTCaZXLncCyhKkgRrP2fgm8BKYG9gH2DvJFvMWiogyZOTvGh166rq9VV1x7Tt5yc5N8l1Sc5MMmc1r1tWVRNVNTFn3rzZii5JUqesVRmoqt+pql8FXgrcBnwIuHN9PzzJc5J8ZIbV+wGHzvC6/5PkqGmLlzD488e9gAuA7dc3nyRJfbC2pwnekORjDC40dCiDvyx44Qb4/M2A3ZI89IM7yaIkRzP4c8YzZnjdncDiJJsleWOz7Pwm32XA1lX1ow2QT5Kksbe2f02wOfBe4OtVdf8G/PwLgP2BryTZEniQwcjDxcAhVXVFkmOmvqC5jfJhwDJgX+B5wN9W1b3ASUneDXwbeP8GzClJ0tha278m+OvZ+PCqKuBdzddM2xwNkGQTBj/8/xDYGPhXYAsGIwRvBW4E9gQOwgsiSZK01tblcsSzrrnnweqWP57BDZLeDnwceGFVPVBVK4ADgeuBOcCFDC6IdNpwEkuS1H1rfQvjYaiq6ZMCVy3/AfDEGdbdzcxzCyRJ0hqMVBkYpt0XLOTTh7+y7RiSJLVupE4TSJKk4bMMSJLUc5YBSZJ6zjIgSVLP9XYC4TV33MmLzz637Ri98qnDX9p2BEnSajgyIElSz1kGJEnqOcuAJEk9ZxmQJKnnLAOSJPWcZUCSpJ6zDEiS1HO9KgNJliaZTDK5cvldbceRJGkkdK4MJNksyReSXJbkiCnLn57kyiRfTLLH6l5bVcuqaqKqJubM22Z4oSVJGmGdKwPA84EbgecCxyX5tWb5XwO/D3wQOLGlbJIkdU4XL0e8CXBPVd2e5HJgrySvBa4G3g08ALyhzYCSJHVJF8vARcDvJrkB+Brwl8DvVdXj240lSVI3da4MVNVdwLNXPU+yGKi28kiS1HVdnDMgSZI2oM6NDExXVd8HFrccQ5KkznJkQJKknuv8yMCjtfuC+Xzq8Je2HUOSpNY5MiBJUs9ZBiRJ6jnLgCRJPdfbOQPX3LGcQ8/+XNsxxt4nDz+o7QiSpDVwZECSpJ6zDEiS1HOWAUmSes4yIElSz1kGJEnqubErA0m2S/LmJB9vO4skSV0wNmWgKQGnA5cAAV7XciRJkjphnK4zsBQoYK+qerDtMJIkdcXYjAwAZwMHALvMtEGSpUkmk0yuXH7X8JJJkjTCOlMGkjwuyeeTXJvkfUk2TrLVqvVVdRXwJuCTSbZY3XtU1bKqmqiqiTnzthlWdEmSRlpnygDwUuAm4MnAVcDxwElTN6iq84GvAS8fejpJkjpqpMtAkh2S/K/m6enAvcDlDErBCuAZSXZqtp2X5JXA84Hr2sgrSVIXjfoEwiXABPCRqroDOCbJLwN/D/wysCPwuSTzgeXAl4AjquprLeWVJKlzRr0M/Afwx0neBPwE2Av4deAtVfUA8M7mS5IkPUojfZqgqn4IPAe4m8G1A84GnlZVn2k1mCRJY2TURwaoqpuB09rOIUnSuBrpkQFJkjT7Rn5kYLbsvmAenzz8oLZjSJLUOkcGJEnqOcuAJEk9ZxmQJKnnejtn4No7VnDYOV9uO8bYO+9lz2o7giRpDRwZkCSp5ywDkiT1nGVAkqSeswxIktRznS0DSZYkObPtHJIkdV1ny4AkSdowWi0DSf4oyRPbzCBJUt+1ep2BqnpHm58vSZJaHBlIckCSbyW5MMm8aev+Msk1SS5Osngt32/bZvtvJDl4hm2WJplMMnnv8jvXfyckSRoDbZ4meAPwN8A3gdeuWphkAfBqYAnwx8Bjm+WbJsmU128C3Dfl+QnA14HnA+9e3QdW1bKqmqiqic3mzd9weyJJUofNehlI8uwkH1zNqrOAPwR+E1jZ/NY+r6ruaJafD/wW8NVm+yuBLae8/knAjc1nnAjsBRzYbL9sNvZFkqRxNIyRgS2AfacO9ze/4V/B4Df4e4F/Bd5RVcth8Bs8sA/wLOApzcu2BHZNsnGS5wInAR9r1r0OeHNV/UpV7VpVp8z6XkmSNCZmfQJhVV2YZA/g40m2AwI8APwQ+Brw/Kr6XpJLkvwdMAnsDBwEfAn4dvNW/xs4A5gHfAN4RVV9o1m3BVCzvS+SJI2jofw1QVWdCpy6hs2OBA4GHs+gAHywqm6Z8h6fBT47ayElSeqpkbmFcVU9AHzqUb528YZNI0lSf3gFQkmSem5kRgaG7QkL5nLey57VdgxJklrnyIAkST1nGZAkqecsA5Ik9ZxlQJKknuvtBMLr7vgZLz/nm23HGDmfeNk+bUeQJA2ZIwOSJPWcZUCSpJ6zDEiS1HOWAUmSes4yIElSz3WiDCSZm+R1SS5qO4skSeNmpMtAki2SnAxcBuwE/HbLkSRJGjujfp2Bw4C9gL2rauX6vlmSpcBSgC23e8z6vp0kSWNhpEcGgAsZjAjsvTYbJ9koyQlJdlrd+qpaVlUTVTWx2bwFGzKnJEmdNVJlIANbr3peVbcCrwD+OcmiKdttleTJzeODkmzfbP8g8E3go8NNLklSd41UGQCeB5w8dUFVfQP4MPBagCQLquonVfXfzSZPBY6asv3FwEZJ9hpGYEmSum7UysD9wFOT7NGMEmyR5FDgSODaZjTgX6a95jvAEwCSbJJkO2BH4KfDDC5JUleN1ATCqrooyWkMhvkXAT8DLgVOqqrPJ3kmcNu0l+0J3JRkY+AqBgXnvVX1vSFGlySps0aqDABU1QeAD8yw+jvA05LsVVVXJNmfwemDF1TVA8Buw8opSdK4GLky8Eiq6vYkxwIfTPJY4DrgqKq6ruVokiR1VqfKAEBVfR74fNs5JEkaF50rAxvKbgu24BMv26ftGJIktW7U/ppAkiQNmWVAkqSeswxIktRzlgFJknqutxMIr79zJSecd33bMUbCKYft0nYESVKLHBmQJKnnLAOSJPWcZUCSpJ6zDEiS1HOWAUmSes4yIElSz418GUjyK0ne0HYOSZLG1ciXAeANwBOSbD91YZLNk7w5yby1faMkS5NMJpn82fLbN3hQSZK6aKTLQJLNqupVVfU7wPJm2XFJDqmqe4CbgPc3y/dI8u0kX0yy3+rer6qWVdVEVU1sMW/h0PZDkqRRNtJlALg0yTZJtgKubZbtBGzbPD4DOLAZHXgd8D7gROCsJP60lyRpLYxMGUiyVZKzpi2eBI4AJoAdk+wGPA64MclGwK7AFsBKBpdWvge4GribQWmQJElrMEr3JljC4If4VDsDBwEB3gF8GfgGcCVwHXAfcGJV3ZPkw8AngD8F/hn49lBSS5LUcaNUBjYGHpdkc+BB4FhgX2CPqvpps807pmy/eOqLq+pyYPch5JQkaayMUhk4HziYwW/0mwL/CTx7ShGQJEmzYGTKQFXdx2ASoCRJGqKRmUAoSZLaMTIjA8O2y/w5nHLYLm3HkCSpdY4MSJLUc5YBSZJ6zjIgSVLP9XbOwM133sep593UdoyRcJZSbCoAABTKSURBVPxhi9qOIElqkSMDkiT1nGVAkqSeswxIktRzlgFJknrOMiBJUs9ZBiRJ6rmRLwNJfiXJG9rOIUnSuBr5MgC8AXhCku3XtGGShUlOSrLpEHJJkjQWRroMJNmsql5VVb8DLG+WHZfkkNVtX1W3A1sBfzzD+y1NMplkcsXy22cttyRJXTLSZQC4NMk2SbYCrm2W7QRsm+Q3k1yT5IwkG095zV8DR6/uzapqWVVNVNXE3HkLZze5JEkdMTJlIMlWSc6atngSOAKYAHZMshvwOOBG4G3AkcAc4NeSrLq08t7APcNJLUlS943SvQmWAHdPW7YzcBAQ4B3Al4FvAF8ETgXOAeYD/wpMJPlY8x5LhxNZkqTuG6UysDHwuCSbAw8CxwL7AntU1U+bbd4xZfsPJvkHBuXg2qr6D+DxwwwsSdI4GJnTBMD5wA+BbwNXA78GPHtKEXiYJLsAZwK3AV8dVkhJksbNyIwMVNV9wOvWtF2SnYB/B+4EPgMcU1U1y/EkSRpbI1MG1lZV/QjYve0ckiSNi1E6TSBJklrQuZGBDWWH+Zty/GGL2o4hSVLrHBmQJKnnLAOSJPWcZUCSpJ7r7ZyBO++4n3PPvrXtGLPmpYdv13YESVJHODIgSVLPWQYkSeo5y4AkST1nGZAkqefGsgwk+XCS57adQ5KkLhjLMiBJktaeZUCSpJ6zDEiS1HOdvuhQkj8HbgeuqqpPJdkG2PIRtl8KLAXYbrudhxNSkqQR17kykOQA4Leq6o1V9bZpq58DvGim11bVMmAZwO5P2K9mL6UkSd3RxdMEC4F9kjx0vd0kC5O8BPhz4HOtJZMkqYM6NzIAfBZ4OvDVJJsBDwDLgf8Ajq2qS5O8uM2AkiR1SefKQFUV8Pbma6Ztjh5SHEmSOq+LpwkkSdIGZBmQJKnnLAOSJPVc5+YMbCjzF2zCSw/fbs0bSpI05hwZkCSp5ywDkiT1nGVAkqSeswxIktRzvZ1AePft9/NvZ93Sdoz18pxXbt92BEnSGHBkQJKknrMMSJLUc5YBSZJ6zjIgSVLPWQYkSeq5TpaBJBcn2X2GdUcn+bNhZ5Ikqas6WQYkSdKG06sykGRpkskkk3ctv63tOJIkjYRelYGqWlZVE1U1sc28bduOI0nSSOjUFQibuQDXtJ1DkqRxMrIjA0kuTzIvyVZJrl+1GKhp282Z9tJNgPuGkVGSpHEwEmUgyaIk35i2+D+B3wSeBuyYZFdgMXDDlNdtBXwrSaa87knAjbObWJKk8TESZQB4JnDJtGU7Af8XOAv4U+ArwDzg4inbbALMBXZOMifJy4EjgE/NdmBJksbFqMwZuBd4UvOb/n3AMcB+wB5V9dNmm3dM2X7JqgdJ3gpcAGwKXAq8oKr+ZxihJUkaB6NSBi4EDga+ySDTfwLPnlIEZlRVpwOnz248SZLG10iUgaq6H3hD2zkkSeqjkSgDbdh64SY855Xbtx1DkqTWjcoEQkmS1BLLgCRJPWcZkCSp5ywDkiT1XG8nEP701vu5/B9vbjvGetn/2B3ajiBJGgOODEiS1HOWAUmSes4yIElSz1kGJEnqOcuAJEk9ZxmQJKnnxqoMJNk8yZuTzGs7iyRJXdG5MpDkyUletLp1VXUPcBPw/hleuzTJZJLJO+6+bTZjSpLUGSNZBpI8J8lHZli9H3Bos82VST6XZO6U9WcAB65udKCqllXVRFVNLNh629mILklS54xkGQA2A3ZL8tA9hpMsSnI08E4GP/B/B/gj4L+AVyTZKMlGwK7AFsDKoaeWJKmDRvVyxBcA+wNfSbIl8CBwG3AxcEhVXZFkAfA3wALgPcBOwCXAfcCJzSkDSZK0BiNZBqqqgHc1XzNt86/Avyb5NHBtVV0PLB5OQkmSxseoniZ4mCSnr2bZ9kneC+wOnDf8VJIkjYdOlIGqOmrq8yTXAF8AAjyzqu5tJZgkSWNgJE8TrElV7d52BkmSxkUnRgYkSdLs6eTIwIaw5XabsP+xO7QdQ5Kk1jkyIElSz1kGJEnqOcuAJEk919s5Aytvuo/vv+/GtmM8aovftGPbESRJY8KRAUmSes4yIElSz1kGJEnqOcuAJEk9ZxmQJKnnLAOSJPWcZUCSpJ7rTBlI8sQkb13DNhslOSHJTsPKJUlS1418GUiyOMnngb8FTkxydZKXr27bqnoQ+Cbw0Rnea2mSySSTt/3kttkLLUlSh4x8GQD+B3glsA2wDFhSVZ9I8tQkX09yaZLHrNq4qi4GNkqy1/Q3qqplVTVRVRPbbrXtsPJLkjTSRv5yxFW1MsmfAx+sqg9NWfW/GYwA/AR4A/C2JJsA84EdgZ8OPawkSR008mWgcRDwumnLzgJOBxYCn0yyMXAVg9GO91bV94YbUZKkbupKGSgGP+QfeGhB1VeBJyX5O+CGqnoA2K2lfJIkdVZXysAFwD8keUtV3ZhkD+CxwC8DLwf2bjWdJEkd1oUJhABvAm4H/j3JDcCZwEXAHsDTq+qWNsNJktRlnRgZqKqfAL/bfEmSpA2oKyMDkiRplnRiZGA2zFm0KYvftGPbMSRJap0jA5Ik9ZxlQJKknrMMSJLUc72dM3DfTfdy419f03aMdbbj7+3edgRJ0phxZECSpJ6zDEiS1HOWAUmSes4yIElSz1kGJEnquU6VgSRvT3Js2zkkSRonnSoDkiRpw7MMSJLUcyNfBpIsTvL6tdx28yRvTjJvhvVLk0wmmbxtxe0bNqgkSR018mWgqr4PTMw0V6ApAHOabe8BbgLeP8N7Lauqiaqa2HbuwtmKLElSp4x8GWi8E3jtDOsOB/58yvMzgANnGh2QJEkPN9JlIMmqeyfsA6yYYbNbgW2TbJRkI2BXYAtg5RAiSpLUeSNdBoCXJLkeeAtw4gzbHAlMAjsB1wEXACc2pwwkSdIajPRdC6vqbODsKYu+CdCMADwZeDPwFOC4qvoZsHjYGSVJ6rqRLgOrk2Rj4LsMRgE+BiytKk8JSJL0KHWuDFTVA8DubeeQJGlcdK4MbCibLtqMHX/PTiFJ0qhPIJQkSbPMMiBJUs9ZBiRJ6jnLgCRJPdfbCYT33fRTbnrf19uOsc4WvelpbUeQJI0ZRwYkSeo5y4AkST1nGZAkqedaKwNJntTWZ0uSpJ8bahlIMifJK5KcB7x2mJ8tSZJWb2hlIMnewLnAQuALwAHD+mxJkjSzYY4MXAf8N3AisAtw5BA/W5IkzWCY1xk4CJgAnlpV967LC5McDtxfVf+yPgGSLAWWAuy8YMf1eStJksbGMEcG/g3YAdj/Ubz2JcDh6xugqpZV1URVTSzcasH6vp0kSWNh1spABrZe9byq7gCOAM5MstM6vM+cqnoV8NtJ5jTL3pHkadO2m5/k3CTXJTlz1baSJOmRzebIwPOAk6cuqKorgPcDxwMk+ask309y4ureIMnGwLeSBHgKcFGzajdg7rTNlwDzgb2AC4DtN8xuSJI03mazDNwPPDXJHs0oweZJDgFeBVybZCHwGmBf4A1JtkryuCSnrHqDqnoA+AHwXAbzDZ6SZBvgccCNSTZL8sZm8/OBy4HLgK2r6kezuG+SJI2NWZtAWFUXJfkH4P8BjwF+CvwH8Naq+hxAc72BK4FtGfxW/2Lgf6a91U7AMuAB4FTgKuAzVfXdJL/MYATib5tJiScleTfwbQYjEJIkaQ1m9a8JqmoZgx/kM60/NsnOwDeBHwMbA09IsgkwB/hD4L6q2nXKy/7vlMdXAouTvBW4EdiTwV8tvGWD7ogkSWOszcsRb5Rkf+DTwClV9SBwOrA18F3gCmBHBr/5r1ZVrQAOBK5nUB4uBA6oqtNmOb4kSWNjmNcZeEiSlwF/weCH+MlV9SGAqrqLdbwYUVXdDZyxwUNKktQTrZSBqjoHOKeNz15l00VbsuhNT1vzhpIkjTlvYSxJUs9ZBiRJ6jnLgCRJPdfKnIFRcN/Nd3PTKRe3HWOdLDphSdsRJEljyJEBSZJ6zjIgSVLPWQYkSeo5y4AkST1nGZAkqec6WQaS3NB2BkmSxkUny4AkSdpwLAOSJPVcr8pAkqVJJpNM3r7irrbjSJI0EsamDCTZJ8mlSa5K8vur26aqllXVRFVNLJy7zbAjSpI0ksamDACvAS4G9gHuTZJ240iS1A2dLgNJnpjkN5qn7wF2By4FLquqai+ZJEnd0fUbFb0EuB+gqq4HXp7kCOBE4EttBpMkqSs6WQaqaufm4UXAPyX5WfN8X+CZwLGtBJMkqYM6fZqgqiaBFwMPAvcCpwH7VdXXWg0mSVKHdHJkYKqq+gHwwbZzSJLUVZ0eGZAkSeuv8yMDj9amO2zNohOWtB1DkqTWOTIgSVLPWQYkSeo5y4AkST3X2zkD9998Fzef+qm2Y6zRDse/uO0IkqQx58iAJEk9ZxmQJKnnLAOSJPWcZUCSpJ6zDEiS1HOWAUmSem4kykCSuUlel+SitrNIktQ3rZaBJFskORm4DNgJ+O0280iS1EdtX3ToMGAvYO+qWjnbH5ZkKbAUYOcF28/2x0mS1Altnya4kMGIwN4b4s2SbJ7kzUnmrW59VS2rqomqmth27jYb4iMlSeq8oZaBDGy96nlV3Qq8AvjnJIumbLdVkic3jw9K8gu/xif5yyTXJLk4yeLm/e4BbgLeP7t7IknS+Bj2yMDzgJOnLqiqbwAfBl4LkGRBVf2kqv672eSpwFFTX5NkAfBqYAnwx8Bjp6w+AzhwptEBSZL0cMMuA/cDT02yRzNKsEWSQ4EjgWub0YB/mfaa7wBPgME5/yTzquoO4A+B84HfAr6aZKMkGwG7AlsAsz4HQZKkcTDUMlBVFwGnAR8Ffgj8F/BS4KSqOgtYANw27WV7Mhj6B3hHVS1v3msZsA/wLOApDOYeXAdcAJzYnDKQJElrMPS/JqiqDwAfmGH1d4CnJdmrqq5Isj+D0wcvaNZfkuTvgElgZ+Ag4EvAt6uqgMWzGl6SpDHU9p8WPkxV3Z7kWOCDSR7L4Df9o6rqumaTI4GDgccD3wY+WFW3tJNWkqTxMFJlAKCqPg98foZ1DwCfGm4iSZLG28iVgWHZZIdt2OH4F7cdQ5Kk1rV90SFJktSyDObd9U+Su4Hvtp1jSLYDbm07xBD0ZT+hP/vqfo6fvuzrqO7n46vqFy7k19vTBMB3q2qi7RDDkGSyD/val/2E/uyr+zl++rKvXdtPTxNIktRzlgFJknquz2VgWdsBhqgv+9qX/YT+7Kv7OX76sq+d2s/eTiCUJEkDfR4ZkCRJWAYkSeq9XpaBJAcl+W6Sa5K8pe08ayPJLkn+LcmVSa5IcmKzfGGSzye5uvnvgmZ5kpzS7OM3k/zSlPc6qtn+6iRHTVn+tCTfal5zSpIMf08fyrJxksuTfLp5vmuSrzbZPpZkTrN8s+b5Nc36xVPe4w+a5d9N8oIpy0fm+CeZn+TsJN9J8t9JDhjHY5rkd5rv228n+WiSzcflmCb5pyQ3J/n2lGWzfgxn+owh7+dfNd+730xyXpL5U9at07F6NN8Pw9zXKetOSlJJtmued/aYPkxV9eoL2Bi4FtgNmMPgNspPaTvXWuR+DPBLzeOtgasY3Lr53cBbmuVvAf6yeXwwcD4Q4FeArzbLFzK4AdRCBreMvg5Y0Kz7WrNtmte+sMX9/V3g/wGfbp5/HDiyefwB4Ljm8euBDzSPjwQ+1jx+SnNsNwN2bY75xqN2/IHTgWObx3OA+eN2TBncXvx7wBZTjuXR43JMgV8FfonB3VNXLZv1YzjTZwx5P58PbNI8/ssp+7nOx2pdvx+Gva/N8l2AC4AfANt1/Zg+bN+G9UGj8gUcAFww5fkfAH/Qdq5HsR+fBJ7H4CqKj2mWPYbBxZQAPgi8Ysr2323Wv4LB3R6Zul2z7jtTlj9suyHv287AF4FfAz7d/A9z65R/dB46hs3/mAc0jzdptsv047pqu1E6/sA2DH5IZtrysTqmDMrA9c0/ips0x/QF43RMGdw+feoPyVk/hjN9xjD3c9q6w4CzVncM1nSsHs3/423sK3A2sC/wfX5eBjp9TFd99fE0wap/mFa5oVnWGc0w2f7AV4FFVfXjZtWNwKLm8Uz7+UjLb1jN8ja8D/g/wIPN822BO6vq/ub51GwP7U+z/q5m+3Xd/zbsCtwCfCiDUyL/mGQrxuyYVtWPgL8Gfgj8mMEx+jrjeUxXGcYxnOkz2vIaBr/lwrrv56P5f3yokhwK/Kiq/mvaqrE4pn0sA52WZC5wDvCmqlo+dV0N6mSn/1Y0ySHAzVX19bazDMEmDIYi/76q9gd+wmBo8CFjckwXAIcyKD+PBbYCDmo11BAN4xi2/X2S5G3A/cBZbWWYTUm2BN4K/NGwPnPYx7SPZeBHDM77rLJzs2zkJdmUQRE4q6rObRbflOQxzfrHADc3y2faz0davvNqlg/bgcBvJPk+8M8MThWcDMxPsupeGlOzPbQ/zfptgNtY9/1vww3ADVX11eb52QzKwbgd0+cC36uqW6rqPuBcBsd5HI/pKsM4hjN9xlAlORo4BHhl8wMM1n0/b2Pdvx+G6QkMyux/Nf827QxclmRHxuWYDut8xKh8Mfht7DoGB3bVBJa92s61FrkDfAR437Tlf8XDJ5y8u3n8Ih4+qeVrzfKFDM5TL2i+vgcsbNZNn9RycMv7vISfTyD8BA+fXPT65vHxPHxy0cebx3vx8AlM1zGYvDRSxx+4BNizefz25niO1TEFngFcAWzZ5DgdeOM4HVN+cc7ArB/DmT5jyPt5EHAlsP207db5WK3r98Ow93Xauu/z8zkDnT6mD+3TsD5olL4YzP68isGs1re1nWctMz+LwZDRN4FvNF8HMzh39kXgauALU77ZApza7OO3gIkp7/Ua4Jrm69VTlk8A325e83cMYZLOGvZ5CT8vA7s1/wNd0/yjsVmzfPPm+TXN+t2mvP5tzb58lymz6Efp+AP7AZPNcf2X5h+NsTumwJ8A32mynMHgh8RYHFPgowzmQtzHYLTnmGEcw5k+Y8j7eQ2D8+Kr/k36wKM9Vo/m+2GY+zpt/ff5eRno7DGd+uXliCVJ6rk+zhmQJElTWAYkSeo5y4AkST1nGZAkqecsA5Ik9ZxlQJKknrMMSJLUc/8fhPDTy+lhZbgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsbCZSB6HCNm"
      },
      "source": [
        "### Finding the max len\n",
        "The contents have different lengths based on words! Detecting the most normal range could help us find the maximum length of the sequences for the preprocessing step. On the other hand, we suppose that the minimum word combination for having a meaningful article for our learning process is 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcKPci-4HQ1k"
      },
      "source": [
        "# compute the words len in each magazine\n",
        "train_df['words_len'] = train_df.tokens.apply(lambda t: len(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7zNHsdJJh1p",
        "outputId": "8228520f-6352-4f4a-e933-4259c6481cf6"
      },
      "source": [
        "def data_gl_than(data, less_than=100.0, greater_than=0.0, col='words_len'):\n",
        "    data_length = data[col].values\n",
        "    data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
        "    data_glt_rate = (data_glt / len(data_length)) * 100\n",
        "    print(f'Texts with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')\n",
        "\n",
        "data_gl_than(train_df, 1e4, 50)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texts with word length of greater than 50 and less than 10000.0 includes 99.55% of the whole!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "gzPuPMJLJIX_",
        "outputId": "670742ce-60a4-42c7-edda-9674bd2f41b4"
      },
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=train_df['words_len']))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of word counts within comments',\n",
        "    xaxis_title_text='Word Count',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"b1d71f95-7255-428d-bca9-419a46b0a3b1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"b1d71f95-7255-428d-bca9-419a46b0a3b1\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'b1d71f95-7255-428d-bca9-419a46b0a3b1',\n",
              "                        [{\"type\": \"histogram\", \"x\": [237, 376, 726, 1799, 2059, 690, 561, 440, 442, 1590, 480, 243, 422, 859, 925, 1773, 3006, 678, 412, 305, 1587, 447, 1769, 1519, 396, 470, 1101, 218, 185, 277, 359, 403, 705, 841, 255, 345, 281, 430, 3224, 460, 509, 563, 722, 54, 1943, 373, 1314, 2580, 500, 571, 633, 377, 367, 457, 1299, 423, 743, 568, 156, 275, 385, 1323, 424, 512, 209, 304, 559, 1732, 247, 449, 1859, 542, 1101, 2233, 2429, 306, 433, 1720, 111, 293, 64, 956, 928, 268, 92, 1168, 307, 1396, 820, 259, 95, 445, 789, 282, 384, 451, 1412, 121, 790, 278, 516, 959, 846, 296, 2139, 314, 247, 160, 219, 920, 550, 299, 647, 80, 309, 435, 320, 323, 469, 800, 270, 82, 262, 1898, 370, 327, 843, 375, 435, 440, 323, 175, 246, 282, 1013, 260, 821, 436, 1282, 91, 300, 1051, 308, 636, 550, 212, 192, 637, 6226, 2396, 347, 1316, 1146, 2808, 379, 290, 4106, 557, 335, 531, 218, 576, 374, 332, 1126, 272, 289, 355, 1077, 1425, 1253, 54, 652, 238, 327, 217, 427, 467, 401, 264, 435, 79, 1561, 462, 422, 1377, 328, 246, 948, 376, 516, 413, 358, 702, 1344, 1181, 234, 462, 1785, 1461, 495, 429, 401, 273, 241, 273, 341, 2943, 222, 371, 244, 128, 557, 1829, 240, 240, 76, 490, 136, 303, 4664, 456, 950, 6792, 589, 378, 1166, 408, 230, 77, 448, 1127, 928, 51, 260, 341, 624, 338, 524, 1255, 327, 242, 100, 84, 427, 90, 337, 531, 1090, 262, 251, 343, 2558, 2045, 875, 534, 503, 550, 411, 366, 75, 462, 333, 1812, 53, 274, 295, 4752, 583, 231, 1148, 1238, 757, 348, 3356, 2139, 319, 278, 309, 350, 49, 1707, 102, 349, 143, 996, 591, 3254, 2219, 2369, 624, 535, 341, 292, 1357, 282, 376, 140, 7727, 1677, 1547, 2902, 696, 564, 249, 233, 616, 558, 263, 277, 271, 71, 1529, 405, 351, 434, 343, 324, 392, 342, 371, 457, 363, 343, 284, 356, 1437, 67, 379, 279, 2446, 307, 668, 261, 332, 1178, 191, 333, 829, 1024, 740, 248, 434, 49, 1823, 233, 196, 261, 356, 588, 644, 320, 262, 168, 299, 964, 32, 1876, 117, 177, 2463, 65, 361, 438, 346, 837, 427, 4339, 1589, 624, 304, 318, 413, 224, 231, 3311, 356, 371, 448, 577, 447, 401, 324, 1170, 359, 238, 224, 1602, 1162, 320, 434, 226, 575, 368, 453, 239, 370, 711, 75, 225, 368, 1118, 287, 913, 72, 333, 370, 371, 813, 347, 648, 550, 296, 99, 724, 458, 809, 484, 1128, 1186, 245, 559, 359, 62, 140, 350, 336, 345, 1590, 1056, 1104, 367, 197, 584, 513, 795, 1086, 756, 224, 379, 314, 928, 475, 578, 686, 2791, 315, 495, 352, 318, 473, 402, 69, 574, 1735, 359, 855, 268, 628, 514, 1994, 343, 282, 219, 1252, 899, 1241, 276, 1037, 867, 355, 781, 281, 357, 576, 429, 259, 612, 350, 264, 312, 78, 502, 394, 864, 351, 993, 208, 488, 731, 90, 1919, 426, 282, 536, 211, 451, 280, 1663, 87, 333, 526, 323, 319, 344, 186, 383, 66, 1201, 2951, 291, 372, 327, 1197, 1542, 309, 142, 394, 1060, 332, 514, 262, 296, 48, 317, 474, 346, 246, 316, 685, 273, 1527, 322, 312, 731, 809, 1345, 308, 923, 1714, 451, 381, 728, 461, 48, 207, 1002, 564, 383, 675, 251, 620, 1173, 69, 2097, 604, 300, 688, 206, 429, 768, 348, 2014, 273, 488, 298, 598, 241, 424, 255, 347, 280, 579, 478, 258, 319, 256, 571, 5194, 1396, 307, 1100, 657, 108, 283, 531, 650, 416, 404, 460, 1356, 84, 450, 274, 338, 238, 324, 420, 313, 1791, 1200, 1439, 267, 3876, 341, 248, 381, 344, 327, 693, 641, 450, 1835, 2864, 212, 834, 251, 1161, 276, 1423, 454, 60, 1055, 338, 585, 210, 617, 618, 260, 346, 1037, 725, 528, 530, 329, 320, 229, 393, 495, 506, 914, 374, 984, 858, 197, 588, 723, 494, 1310, 404, 1734, 1870, 1710, 1299, 416, 222, 468, 1043, 241, 236, 1079, 177, 1322, 394, 248, 1658, 297, 427, 1556, 166, 476, 1146, 540, 277, 276, 1419, 260, 280, 282, 602, 213, 356, 435, 1758, 235, 490, 1261, 260, 110, 48, 724, 1039, 1652, 1461, 1013, 1475, 848, 230, 247, 1828, 902, 570, 260, 2198, 334, 314, 536, 1013, 354, 2460, 54, 1078, 415, 600, 450, 328, 428, 1099, 371, 1218, 213, 1538, 4722, 87, 217, 1900, 363, 640, 245, 1049, 323, 428, 252, 1255, 2602, 198, 426, 820, 1313, 243, 357, 1483, 384, 230, 999, 1272, 469, 343, 425, 61, 189, 531, 357, 1563, 313, 399, 815, 325, 197, 277, 272, 3273, 780, 577, 105, 390, 516, 60, 252, 4470, 759, 366, 509, 298, 1696, 1639, 907, 76, 66, 423, 67, 292, 531, 329, 411, 361, 416, 1973, 807, 231, 1330, 463, 997, 200, 2393, 614, 418, 360, 293, 894, 375, 1803, 1383, 338, 321, 673, 161, 815, 449, 360, 978, 343, 499, 444, 71, 437, 197, 298, 449, 289, 212, 149, 478, 985, 489, 56, 616, 613, 365, 1843, 306, 360, 328, 408, 512, 342, 315, 422, 346, 615, 445, 325, 319, 107, 1524, 468, 420, 1724, 351, 1157, 351, 275, 573, 341, 385, 481, 203, 324, 63, 258, 1267, 196, 571, 1066, 335, 628, 1795, 535, 2299, 734, 966, 1265, 681, 271, 263, 1406, 336, 350, 494, 199, 363, 816, 628, 293, 2010, 357, 441, 422, 227, 250, 1953, 284, 381, 1525, 225, 1115, 244, 547, 438, 387, 550, 670, 612, 1134, 1932, 397, 386, 900, 2541, 295, 1113, 231, 1814, 751, 1773, 275, 819, 77, 239, 3544, 220, 827, 1102, 415, 1064, 1037, 396, 292, 62, 526, 65, 506, 798, 296, 71, 263, 141, 1271, 750, 281, 633, 619, 507, 256, 238, 533, 1600, 345, 128, 2838, 482, 586, 81, 727, 479, 251, 527, 58, 533, 513, 760, 430, 757, 391, 278, 330, 376, 1900, 70, 968, 243, 91, 1619, 182, 556, 307, 397, 3099, 278, 242, 329, 403, 882, 262, 1177, 364, 949, 506, 465, 77, 220, 2584, 162, 347, 256, 169, 195, 234, 1747, 289, 482, 347, 530, 457, 347, 586, 372, 280, 914, 732, 883, 330, 281, 2603, 301, 636, 62, 332, 767, 273, 2154, 254, 2164, 407, 345, 1309, 368, 647, 64, 428, 769, 472, 689, 228, 264, 1081, 942, 440, 572, 793, 218, 473, 259, 1084, 277, 422, 188, 422, 398, 609, 366, 350, 548, 1170, 86, 513, 254, 1957, 1146, 894, 279, 1661, 339, 303, 231, 422, 1671, 3035, 1276, 273, 747, 368, 1379, 302, 332, 350, 949, 1111, 594, 561, 649, 588, 193, 634, 936, 883, 460, 285, 286, 87, 1400, 3792, 488, 261, 2155, 247, 491, 76, 4701, 435, 1616, 713, 561, 580, 359, 1376, 580, 552, 262, 72, 313, 963, 401, 391, 1509, 340, 418, 233, 264, 365, 223, 1662, 47, 500, 706, 261, 2222, 255, 398, 207, 693, 1168, 433, 787, 491, 1571, 261, 282, 796, 1071, 324, 73, 462, 1132, 164, 232, 347, 338, 336, 106, 521, 6188, 2741, 450, 250, 376, 86, 385, 591, 648, 351, 57, 606, 408, 33, 465, 411, 503, 1184, 967, 910, 316, 71, 289, 198, 982, 326, 403, 167, 235, 131, 244, 628, 524, 86, 502, 891, 318, 535, 73, 72, 956, 238, 362, 313, 974, 326, 180, 545, 277, 261, 450, 74, 370, 855, 300, 1692, 1060, 852, 375, 1049, 1047, 80, 99, 576, 613, 2242, 474, 532, 46, 324, 349, 388, 297, 1269, 497, 296, 376, 845, 361, 296, 394, 53, 456, 1267, 527, 311, 826, 338, 236, 369, 839, 342, 344, 247, 461, 267, 226, 478, 200, 1214, 820, 289, 501, 896, 1052, 1535, 89, 262, 443, 953, 867, 785, 529, 63, 502, 533, 182, 455, 288, 433, 322, 258, 216, 1843, 398, 634, 1206, 418, 399, 245, 494, 220, 720, 96, 876, 625, 1007, 1676, 140, 85, 1327, 624, 523, 280, 313, 421, 297, 275, 722, 301, 1656, 259, 1580, 679, 255, 976, 642, 676, 325, 550, 319, 667, 93, 1136, 301, 872, 245, 626, 1125, 1374, 1406, 275, 1560, 335, 368, 574, 435, 356, 462, 225, 2625, 1289, 405, 338, 96, 625, 330, 1311, 302, 241, 542, 1664, 311, 355, 618, 234, 362, 992, 368, 77, 2445, 780, 91, 368, 369, 409, 202, 767, 371, 312, 309, 190, 318, 285, 1401, 2467, 2129, 503, 365, 329, 594, 453, 353, 398, 922, 286, 316, 997, 64, 1163, 1697, 329, 398, 253, 531, 448, 474, 361, 327, 762, 1165, 270, 191, 943, 367, 391, 455, 468, 279, 728, 377, 424, 870, 2458, 4328, 371, 580, 384, 114, 262, 540, 355, 429, 923, 675, 686, 28, 251, 585, 221, 151, 353, 231, 405, 509, 214, 390, 692, 397, 342, 232, 857, 267, 126, 263, 1393, 255, 265, 674, 437, 581, 58, 130, 273, 334, 292, 313, 140, 1277, 228, 369, 328, 168, 305, 721, 208, 1697, 1046, 66, 246, 918, 53, 216, 315, 565, 1845, 311, 296, 450, 71, 327, 1999, 591, 1736, 889, 359, 858, 364, 522, 59, 158, 446, 205, 381, 290, 541, 50, 407, 761, 87, 261, 1018, 938, 326, 440, 291, 271, 633, 225, 196, 499, 438, 84, 263, 373, 471, 73, 526, 90, 744, 269, 450, 272, 1399, 229, 588, 585, 367, 440, 64, 353, 311, 429, 481, 56, 295, 184, 342, 51, 549, 409, 562, 740, 418, 399, 515, 351, 51, 282, 869, 362, 421, 406, 134, 331, 1283, 237, 319, 571, 245, 279, 1192, 790, 881, 242, 1551, 560, 714, 666, 1147, 3185, 203, 292, 587, 230, 335, 546, 568, 70, 2383, 1073, 322, 1539, 1466, 530, 942, 1333, 381, 237, 1171, 1291, 754, 282, 1009, 292, 987, 2008, 221, 1005, 270, 790, 300, 746, 299, 2362, 968, 469, 263, 1817, 856, 1140, 513, 324, 66, 351, 404, 330, 77, 67, 362, 339, 420, 307, 354, 2488, 67, 421, 785, 251, 436, 262, 299, 65, 409, 230, 1455, 394, 1483, 1496, 922, 2824, 313, 1294, 1111, 404, 1287, 368, 61, 204, 4269, 239, 185, 330, 515, 437, 2192, 297, 280, 839, 314, 266, 357, 2266, 288, 307, 278, 654, 125, 391, 382, 539, 355, 322, 1082, 578, 47, 2407, 70, 73, 1214, 331, 745, 574, 153, 402, 323, 395, 65, 69, 353, 225, 986, 209, 223, 1115, 2347, 130, 270, 283, 381, 1534, 234, 245, 1043, 1199, 376, 436, 302, 315, 631, 769, 246, 1068, 725, 1261, 439, 158, 510, 554, 269, 875, 481, 720, 682, 481, 378, 496, 540, 385, 240, 376, 587, 75, 198, 215, 1628, 682, 532, 584, 59, 55, 824, 551, 413, 293, 232, 268, 862, 509, 359, 405, 527, 882, 493, 383, 980, 303, 380, 59, 397, 711, 1344, 954, 94, 1138, 452, 273, 435, 1040, 466, 244, 436, 267, 333, 519, 1771, 319, 407, 372, 426, 355, 325, 1208, 1504, 372, 1719, 298, 370, 347, 1093, 573, 317, 101, 252, 421, 297, 207, 492, 958, 303, 3080, 226, 76, 7514, 248, 253, 281, 459, 600, 78, 438, 179, 268, 401, 301, 1574, 813, 784, 154, 931, 88, 2320, 326, 183, 1821, 259, 551, 267, 1551, 352, 252, 322, 57, 351, 381, 755, 609, 705, 1026, 729, 508, 2479, 4199, 289, 4712, 144, 335, 51, 279, 245, 338, 370, 300, 1017, 179, 893, 54, 990, 315, 319, 469, 619, 407, 702, 893, 330, 1797, 1738, 332, 370, 273, 1544, 1007, 1337, 1481, 354, 305, 696, 367, 2946, 350, 1216, 144, 369, 266, 48, 494, 81, 346, 1906, 1594, 344, 52, 239, 236, 345, 408, 214, 434, 237, 415, 427, 84, 1975, 417, 315, 276, 325, 972, 280, 2816, 1244, 630, 636, 318, 244, 308, 1862, 2178, 572, 1649, 525, 1540, 1109, 539, 1321, 281, 264, 152, 1417, 392, 3464, 617, 390, 333, 321, 409, 1808, 329, 215, 197, 411, 500, 348, 392, 462, 564, 294, 676, 452, 745, 715, 270, 1541, 226, 1052, 234, 400, 1322, 398, 392, 343, 123, 339, 614, 481, 1560, 460, 250, 1661, 328, 944, 363, 307, 934, 939, 1450, 352, 259, 413, 988, 267, 1391, 317, 449, 342, 1222, 67, 338, 387, 232, 283, 57, 332, 359, 329, 294, 4006, 276, 317, 1575, 1850, 1596, 197, 774, 332, 369, 3000, 353, 344, 410, 417, 1366, 565, 291, 579, 366, 356, 741, 387, 496, 144, 162, 119, 593, 497, 770, 371, 458, 860, 356, 286, 72, 178, 818, 283, 365, 264, 1117, 249, 441, 706, 1416, 415, 234, 277, 123, 787, 329, 277, 747, 719, 399, 191, 221, 378, 314, 256, 439, 232, 809, 370, 267, 348, 1246, 263, 450, 534, 191, 220, 134, 569, 232, 850, 340, 264, 328, 984, 974, 213, 70, 121, 4681, 766, 237, 376, 212, 493, 1176, 193, 1087, 820, 7069, 2180, 765, 1354, 233, 322, 282, 771, 60, 751, 262, 1011, 333, 621, 360, 1208, 590, 827, 2061, 436, 391, 372, 466, 1627, 516, 238, 431, 378, 403, 266, 632, 1695, 1558, 1026, 390, 332, 319, 77, 2571, 913, 1059, 644, 243, 540, 73, 1723, 1206, 325, 49, 60, 1122, 769, 498, 294, 294, 386, 549, 133, 296, 231, 268, 441, 796, 419, 255, 308, 507, 449, 329, 253, 1542, 798, 554, 309, 151, 999, 219, 1340, 449, 385, 144, 467, 532, 112, 842, 616, 280, 74, 347, 1291, 163, 543, 443, 92, 1719, 403, 896, 925, 452, 280, 699, 339, 931, 824, 1155, 455, 340, 85, 953, 553, 216, 271, 621, 125, 712, 353, 261, 266, 414, 299, 487, 264, 439, 432, 323, 267, 674, 498, 1113, 1206, 255, 159, 51, 141, 457, 890, 567, 364, 348, 351, 231, 282, 2605, 1145, 554, 311, 258, 885, 300, 373, 257, 505, 485, 270, 347, 74, 572, 313, 330, 494, 117, 444, 311, 75, 283, 326, 1689, 354, 1768, 440, 320, 369, 960, 451, 371, 364, 407, 3379, 278, 435, 254, 63, 401, 445, 333, 159, 296, 84, 414, 336, 252, 493, 89, 914, 506, 503, 440, 115, 1544, 1213, 477, 717, 979, 231, 325, 365, 550, 230, 334, 347, 538, 298, 1370, 326, 383, 920, 417, 1366, 60, 70, 356, 334, 806, 1441, 884, 348, 383, 100, 369, 71, 437, 167, 492, 243, 3650, 50, 558, 1447, 427, 1448, 1252, 327, 78, 315, 261, 60, 1236, 252, 391, 229, 332, 391, 493, 426, 237, 237, 52, 1210, 3042, 913, 1023, 322, 477, 80, 234, 998, 340, 420, 714, 475, 1073, 896, 930, 238, 68, 567, 3626, 622, 201, 4198, 359, 626, 1885, 307, 303, 274, 111, 483, 312, 442, 322, 267, 348, 69, 667, 1364, 186, 341, 340, 658, 1260, 952, 686, 285, 214, 344, 377, 455, 387, 55, 379, 234, 345, 428, 410, 364, 360, 266, 740, 676, 466, 1210, 751, 319, 403, 637, 523, 907, 333, 244, 428, 1177, 1945, 387, 519, 301, 1766, 124, 292, 1786, 307, 877, 562, 1328, 770, 1067, 297, 504, 1076, 70, 221, 255, 355, 772, 264, 1823, 502, 1778, 251, 2033, 891, 1679, 287, 232, 353, 493, 248, 333, 258, 1524, 298, 229, 106, 514, 469, 263, 302, 312, 209, 339, 371, 738, 404, 300, 203, 730, 499, 511, 352, 2422, 352, 655, 511, 567, 346, 354, 756, 140, 687, 240, 71, 1046, 81, 464, 324, 1747, 238, 403, 525, 396, 609, 306, 288, 501, 267, 791, 340, 174, 326, 770, 333, 339, 282, 257, 1124, 250, 270, 255, 11039, 387, 599, 428, 2323, 281, 492, 249, 1322, 947, 60, 198, 867, 1686, 577, 338, 453, 187, 1048, 454, 250, 58, 852, 582, 1742, 68, 442, 1075, 583, 332, 63, 199, 329, 419, 1745, 276, 474, 325, 741, 269, 2867, 973, 248, 316, 1879, 391, 606, 2051, 439, 256, 246, 708, 551, 433, 435, 310, 631, 938, 261, 500, 151, 273, 216, 958, 417, 309, 207, 953, 480, 578, 315, 314, 463, 566, 958, 173, 308, 237, 1258, 397, 621, 1442, 216, 886, 1840, 55, 57, 347, 165, 529, 1065, 334, 509, 263, 1319, 929, 387, 702, 186, 5966, 302, 1378, 1519, 97, 268, 396, 279, 346, 504, 1521, 211, 196, 328, 785, 698, 349, 327, 782, 316, 1059, 1814, 586, 518, 540, 386, 1013, 661, 172, 248, 1259, 539, 399, 245, 500, 786, 1561, 1181, 558, 665, 249, 344, 531, 334, 292, 106, 128, 408, 1530, 367, 5261, 620, 449, 987, 259, 320, 305, 223, 1288, 288, 256, 267, 643, 1109, 611, 343, 596, 759, 1401, 860, 371, 1829, 638, 2160, 2189, 269, 298, 394, 266, 260, 4878, 343, 306, 121, 1428, 349, 338, 1634, 384, 215, 1274, 150, 56, 2022, 1182, 255, 508, 2380, 274, 406, 419, 1533, 263, 494, 335, 268, 324, 440, 99, 1866, 334, 288, 226, 279, 547, 319, 263, 267, 262, 291, 528, 385, 55, 1270, 1731, 366, 1210, 255, 387, 272, 2100, 480, 253, 554, 340, 1069, 303, 630, 630, 1183, 449, 314, 317, 482, 89, 332, 241, 323, 257, 272, 205, 462, 385, 1751, 665, 517, 87, 1568, 533, 238, 2151, 370, 547, 60, 263, 2693, 707, 2532, 1173, 287, 779, 533, 1120, 2523, 351, 669, 252, 338, 2456, 403, 1659, 135, 342, 1079, 619, 471, 943, 214, 2634, 750, 578, 1171, 279, 390, 592, 540, 291, 56, 744, 346, 747, 70, 2026, 1195, 296, 231, 850, 449, 775, 690, 410, 458, 287, 231, 373, 280, 369, 341, 331, 279, 3628, 551, 931, 577, 285, 976, 286, 314, 640, 485, 1672, 434, 422, 330, 335, 328, 225, 685, 1327, 369, 533, 62, 639, 465, 639, 863, 1327, 2137, 429, 381, 1668, 335, 2260, 2604, 399, 1113, 895, 1015, 333, 430, 514, 444, 691, 480, 125, 659, 737, 520, 427, 258, 445, 378, 479, 207, 7477, 330, 587, 1156, 504, 379, 499, 458, 188, 278, 2838, 338, 304, 528, 1068, 394, 425, 1134, 442, 24, 426, 771, 346, 313, 928, 303, 401, 3287, 1549, 685, 306, 771, 232, 102, 83, 655, 1030, 467, 60, 630, 535, 60, 702, 339, 1557, 540, 135, 299, 336, 251, 1345, 170, 328, 356, 1773, 207, 323, 2205, 737, 362, 252, 338, 3699, 301, 229, 119, 325, 339, 293, 325, 368, 848, 3687, 1110, 603, 598, 356, 84, 652, 359, 64, 347, 556, 319, 543, 456, 1465, 210, 229, 336, 46, 1996, 1655, 484, 61, 1875, 656, 578, 342, 99, 402, 153, 422, 609, 315, 534, 255, 501, 289, 284, 284, 433, 631, 512, 1799, 886, 333, 279, 76, 89, 651, 346, 218, 417, 120, 467, 411, 1051, 399, 61, 234, 335, 1106, 410, 1203, 304, 459, 375, 942, 2236, 880, 83, 356, 1159, 451, 429, 310, 1002, 286, 543, 422, 227, 349, 365, 238, 83, 654, 930, 304, 445, 284, 789, 738, 296, 789, 837, 393, 445, 347, 411, 529, 422, 196, 336, 244, 272, 694, 111, 372, 51, 1506, 437, 597, 615, 1687, 246, 641, 967, 430, 1862, 488, 542, 1038, 2202, 1668, 829, 1653, 462, 80, 304, 1991, 319, 318, 225, 521, 572, 4931, 303, 389, 1422, 713, 1554, 226, 172, 2337, 1302, 551, 2467, 554, 90, 289, 1271, 233, 1462, 224, 378, 324, 473, 2276, 549, 329, 227, 819, 466, 203, 908, 387, 169, 435, 375, 1490, 418, 241, 897, 424, 459, 53, 1215, 606, 340, 601, 279, 192, 1699, 2682, 248, 1075, 256, 3969, 561, 675, 401, 355, 325, 96, 226, 69, 2175, 1545, 525, 1066, 488, 366, 250, 389, 66, 57, 252, 1604, 244, 374, 798, 792, 142, 437, 885, 241, 1499, 2245, 572, 1528, 1935, 488, 874, 592, 797, 603, 1131, 452, 977, 480, 576, 230, 562, 7235, 707, 92, 462, 727, 867, 710, 325, 600, 451, 349, 2403, 2534, 77, 442, 729, 1579, 1196, 1577, 245, 198, 347, 385, 425, 402, 320, 51, 524, 1770, 374, 130, 1224, 1494, 783, 607, 955, 1274, 788, 1592, 1321, 347, 1018, 380, 408, 540, 358, 317, 1753, 170, 64, 1482, 459, 525, 219, 570, 65, 53, 232, 466, 344, 132, 491, 383, 770, 348, 105, 238, 321, 159, 388, 1799, 781, 58, 517, 391, 284, 228, 350, 280, 351, 695, 318, 60, 614, 1140, 663, 410, 647, 516, 1346, 2454, 537, 314, 364, 1166, 57, 430, 697, 925, 68, 498, 1799, 728, 380, 390, 1006, 323, 1231, 2197, 715, 275, 494, 353, 1655, 508, 232, 586, 941, 256, 198, 518, 391, 1498, 313, 803, 1591, 1939, 356, 321, 64, 706, 372, 213, 57, 536, 1342, 482, 145, 1750, 201, 2223, 284, 364, 350, 280, 465, 472, 273, 557, 407, 598, 266, 323, 2935, 260, 416, 2562, 241, 1367, 448, 374, 112, 527, 454, 308, 290, 451, 2960, 378, 48, 1095, 616, 63, 2024, 597, 778, 752, 778, 593, 1123, 389, 630, 495, 310, 356, 503, 1370, 1213, 304, 3097, 523, 1097, 392, 1990, 354, 316, 941, 369, 380, 427, 869, 393, 1490, 1170, 389, 445, 314, 256, 360, 551, 243, 714, 1418, 338, 522, 192, 329, 1551, 444, 176, 429, 259, 604, 390, 1781, 1708, 547, 300, 2074, 578, 303, 419, 371, 474, 2658, 1011, 438, 2363, 564, 93, 489, 2039, 911, 1425, 396, 798, 466, 595, 1571, 352, 384, 641, 61, 314, 2045, 410, 243, 593, 297, 132, 332, 2190, 433, 373, 1133, 495, 841, 2048, 1346, 199, 253, 282, 1152, 1140, 995, 733, 1061, 442, 280, 1126, 1321, 263, 367, 320, 1016, 305, 80, 175, 279, 2128, 915, 637, 377, 1083, 321, 339, 233, 1591, 351, 224, 394, 310, 211, 476, 1523, 257, 554, 465, 686, 207, 276, 474, 600, 1161, 190, 1049, 1680, 264, 84, 266, 319, 1045, 243, 208, 4331, 835, 304, 435, 525, 662, 750, 420, 436, 1463, 246, 1113, 60, 301, 357, 2699, 573, 2206, 425, 327, 736, 359, 416, 610, 284, 467, 538, 213, 244, 731, 1842, 79, 721, 591, 2617, 558, 338, 378, 1765, 307, 219, 241, 144, 2470, 705, 506, 280, 588, 2962, 644, 2130, 356, 1183, 117, 1367, 302, 289, 162, 78, 141, 297, 489, 130, 1259, 1284, 252, 1442, 455, 283, 68, 263, 812, 1727, 339, 257, 939, 1496, 2432, 1149, 684, 915, 967, 285, 920, 105, 445, 454, 279, 1599, 586, 582, 281, 1253, 402, 1011, 395, 635, 603, 650, 1245, 319, 405, 506, 452, 191, 765, 327, 1561, 260, 73, 185, 160, 239, 97, 1233, 2398, 948, 2328, 195, 416, 1642, 325, 700, 48, 1134, 491, 543, 426, 844, 871, 287, 286, 1841, 614, 1788, 319, 1042, 350, 310, 272, 97, 405, 474, 253, 318, 899, 2037, 258, 520, 271, 87, 260, 989, 59, 238, 62, 250, 1064, 564, 1406, 706, 491, 2364, 76, 319, 293, 1747, 226, 224, 1441, 1057, 1814, 2184, 392, 594, 251, 424, 293, 345, 202, 206, 524, 281, 715, 324, 454, 480, 2841, 558, 458, 623, 648, 259, 541, 236, 1064, 301, 357, 1009, 567, 213, 1304, 520, 813, 828, 606, 2566, 878, 551, 546, 364, 248, 1118, 387, 1879, 492, 395, 615, 340, 652, 596, 1898, 430, 278, 60, 476, 325, 472, 381, 1288, 64, 254, 58, 1249, 88, 1345, 246, 1370, 874, 365, 929, 745, 1091, 1730, 560, 851, 1218, 389, 530, 100, 341, 2354, 66, 419, 1494, 894, 2023, 472, 551, 60, 443, 1894, 867, 70, 1061, 674, 2808, 275, 488, 333, 1613, 62, 1054, 3347, 1796, 215, 352, 555, 351, 75, 323, 328, 304, 598, 75, 729, 471, 809, 1037, 307, 206, 342, 672, 664, 365, 844, 438, 203, 275, 240, 572, 476, 202, 217, 717, 69, 1695, 514, 51, 229, 442, 1659, 515, 795, 287, 799, 228, 1833, 238, 501, 527, 497, 939, 395, 257, 315, 464, 103, 622, 76, 161, 1295, 1679, 1098, 925, 271, 131, 808, 461, 64, 763, 2044, 291, 418, 427, 1140, 403, 544, 365, 930, 281, 101, 264, 77, 405, 341, 360, 576, 291, 128, 520, 502, 330, 1068, 179, 571, 402, 877, 68, 360, 539, 398, 406, 675, 749, 5315, 190, 297, 348, 120, 358, 738, 1810, 99, 474, 558, 479, 297, 417, 251, 242, 306, 1350, 980, 573, 393, 590, 204, 2133, 871, 423, 1239, 589, 1081, 522, 508, 4769, 341, 478, 336, 312, 288, 835, 548, 2087, 3361, 309, 1133, 411, 675, 239, 248, 458, 201, 61, 401, 357, 64, 1255, 542, 809, 1369, 416, 276, 416, 945, 998, 1551, 96, 1705, 615, 1196, 1339, 325, 5363, 230, 1146, 228, 394, 695, 274, 702, 359, 340, 1294, 94, 387, 1518, 789, 623, 844, 58, 74, 419, 1068, 559, 536, 362, 215, 1868, 354, 617, 390, 896, 408, 901, 564, 530, 537, 499, 474, 866, 1098, 788, 886, 297, 63, 311, 1046, 64, 351, 562, 275, 274, 596, 2082, 336, 353, 1391, 417, 1502, 279, 235, 721, 2160, 1073, 95, 130, 351, 388, 435, 241, 345, 420, 310, 339, 1784, 1125, 368, 1581, 1039, 155, 198, 147, 381, 208, 539, 2101, 570, 439, 610, 287, 217, 520, 290, 67, 1855, 282, 186, 93, 71, 83, 854, 362, 429, 428, 597, 325, 403, 304, 387, 405, 465, 331, 1421, 288, 1058, 325, 1467, 955, 373, 510, 502, 665, 342, 494, 80, 1353, 319, 369, 985, 462, 3347, 7479, 1195, 182, 361, 432, 340, 282, 1865, 612, 538, 253, 1070, 350, 443, 810, 374, 594, 446, 313, 517, 618, 346, 276, 214, 1458, 771, 462, 341, 374, 826, 346, 255, 302, 318, 323, 243, 504, 6803, 296, 434, 315, 590, 351, 299, 884, 247, 1056, 1397, 422, 67, 60, 309, 345, 899, 157, 365, 366, 673, 1092, 227, 358, 212, 840, 315, 241, 253, 374, 1042, 292, 550, 4561, 298, 350, 1293, 326, 1395, 306, 77, 847, 287, 263, 748, 226, 67, 299, 811, 249, 796, 275, 360, 403, 576, 238, 77, 2349, 585, 285, 374, 1195, 478, 410, 2924, 3228, 1474, 1476, 4500, 398, 971, 252, 379, 103, 451, 72, 261, 735, 498, 1145, 282, 934, 520, 146, 918, 91, 439, 533, 638, 418, 343, 1415, 407, 487, 309, 1573, 269, 604, 1648, 949, 1484, 291, 2277, 974, 67, 278, 360, 59, 596, 1011, 516, 361, 1299, 916, 406, 478, 389, 1964, 232, 265, 260, 239, 266, 1353, 1970, 589, 99, 531, 1454, 123, 283, 73, 236, 154, 174, 799, 136, 289, 234, 279, 704, 390, 387, 350, 209, 290, 297, 288, 286, 1362, 1041, 236, 301, 538, 568, 830, 524, 566, 265, 290, 391, 462, 321, 400, 310, 63, 217, 76, 305, 718, 62, 452, 350, 1182, 1121, 604, 284, 325, 926, 1109, 278, 1181, 518, 620, 223, 542, 262, 988, 268, 1658, 329, 5440, 1178, 418, 775, 275, 1320, 665, 3618, 198, 1144, 833, 2181, 1260, 2493, 601, 255, 2493, 1857, 238, 485, 692, 313, 482, 585, 291, 685, 443, 54, 1126, 309, 348, 1218, 1484, 324, 451, 67, 270, 269, 208, 553, 506, 315, 220, 1201, 284, 1669, 1098, 221, 336, 241, 513, 270, 382, 1029, 406, 1712, 839, 313, 984, 871, 1624, 565, 501, 967, 753, 515, 840, 499, 578, 1856, 366, 304, 203, 302, 2840, 432, 286, 249, 311, 3205, 496, 654, 454, 651, 317, 570, 259, 238, 1256, 77, 678, 1216, 372, 75, 1395, 233, 303, 321, 1375, 271, 2047, 3449, 330, 344, 300, 205, 262, 1335, 123, 477, 507, 654, 367, 399, 315, 67, 375, 245, 343, 1914, 228, 1316, 371, 100, 408, 1518, 1169, 2791, 2084, 258, 463, 314, 546, 995, 241, 211, 580, 248, 285, 493, 312, 378, 336, 307, 1736, 1926, 288, 357, 1574, 300, 75, 1516, 303, 173, 274, 340, 324, 189, 689, 394, 1698, 241, 335, 3134, 1322, 794, 364, 363, 648, 683, 289, 285, 4407, 464, 545, 312, 300, 290, 356, 184, 247, 329, 403, 502, 262, 401, 209, 219, 3600, 273, 244, 509, 2688, 292, 78, 408, 362, 325, 737, 342, 504, 601, 438, 518, 608, 709, 741, 1384, 2542, 230, 246, 1085, 380, 1911, 1042, 705, 298, 153, 373, 601, 592, 283, 96, 585, 328, 336, 986, 220, 247, 625, 393, 846, 346, 367, 623, 353, 198, 334, 617, 1583, 326, 441, 390, 4247, 225, 78, 460, 616, 1178, 356, 1296, 208, 298, 942, 402, 620, 425, 215, 69, 726, 337, 873, 265, 421, 718, 246, 307, 866, 1763, 1319, 1212, 319, 698, 434, 365, 283, 339, 410, 1167, 378, 1326, 1720, 289, 266, 269, 1461, 1190, 1232, 357, 413, 495, 1972, 2033, 2354, 434, 425, 696, 335, 249, 1768, 2435, 209, 526, 4863, 279, 462, 228, 348, 1516, 1477, 440, 280, 1046, 435, 308, 3114, 475, 581, 386, 336, 258, 502, 220, 524, 232, 868, 1650, 314, 280, 369, 306, 282, 361, 738, 298, 64, 412, 457, 662, 370, 325, 735, 310, 708, 97, 366, 807, 360, 463, 711, 2603, 372, 265, 276, 3258, 1676, 1282, 357, 1231, 531, 2912, 1000, 430, 377, 249, 559, 2023, 235, 220, 262, 448, 125, 414, 211, 1294, 124, 329, 389, 310, 399, 577, 680, 220, 352, 359, 311, 245, 764, 377, 70, 25, 1901, 948, 390, 1028, 343, 348, 339, 485, 305, 312, 724, 408, 607, 567, 461, 2119, 942, 414, 80, 182, 302, 197, 342, 998, 396, 470, 286, 506, 1555, 328, 463, 482, 337, 80, 795, 642, 631, 2230, 291, 311, 1312, 625, 459, 286, 1041, 1370, 324, 1086, 280, 226, 681, 245, 1373, 1926, 730, 248, 347, 1718, 238, 1545, 915, 2528, 521, 479, 748, 233, 716, 221, 1454, 1475, 339, 74, 539, 2370, 941, 137, 60, 3305, 237, 508, 255, 565, 370, 1696, 364, 369, 2399, 1530, 168, 523, 3553, 382, 312, 866, 1268, 783, 251, 1308, 233, 612, 511, 142, 345, 1195, 1641, 875, 270, 1584, 313, 312, 652, 611, 791, 395, 414, 286, 292, 1663, 322, 367, 5421, 370, 334, 313, 334, 130, 490, 2965, 561, 1251, 235, 1470, 451, 433, 3346, 389, 268, 2331, 2246, 345, 923, 285, 232, 380, 249, 98, 284, 418, 260, 2194, 2254, 281, 122, 516, 715, 1770, 47, 1378, 294, 379, 264, 1854, 1363, 782, 930, 473, 3268, 2175, 543, 249, 243, 392, 1262, 1523, 363, 135, 421, 902, 349, 910, 72, 257, 380, 368, 390, 294, 647, 618, 1934, 298, 637, 1432, 241, 897, 790, 1064, 168, 288, 569, 505, 445, 408, 384, 428, 1810, 2685, 572, 1819, 288, 1184, 332, 662, 870, 465, 335, 1192, 379, 317, 825, 341, 1096, 1197, 53, 388, 466, 306, 816, 587, 406, 311, 640, 1901, 1390, 102, 858, 563, 70, 479, 515, 287, 262, 389, 182, 469, 717, 353, 603, 250, 169, 4021, 362, 240, 427, 437, 698, 468, 458, 519, 1922, 232, 331, 1434, 308, 870, 244, 618, 705, 349, 378, 349, 543, 591, 418, 2900, 337, 487, 64, 213, 332, 449, 197, 2706, 989, 172, 756, 631, 348, 2431, 265, 339, 477, 385, 639, 996, 398, 632, 1215, 502, 1212, 1737, 611, 334, 100, 233, 481, 623, 62, 936, 1957, 254, 757, 1834, 300, 47, 113, 391, 1870, 1019, 564, 379, 90, 427, 294, 427, 527, 309, 440, 243, 1139, 338, 703, 254, 900, 742, 308, 359, 310, 584, 264, 798, 314, 1612, 236, 811, 464, 289, 442, 259, 492, 530, 611, 325, 418, 355, 148, 437, 492, 268, 1151, 243, 2235, 690, 414, 1325, 327, 557, 233, 769, 526, 1470, 437, 451, 236, 178, 305, 248, 1251, 351, 1393, 387, 1410, 987, 455, 1878, 1133, 801, 239, 491, 165, 301, 1038, 2296, 983, 1367, 250, 377, 908, 236, 888, 618, 306, 2181, 2310, 1444, 502, 361, 954, 212, 1149, 1185, 552, 37, 571, 872, 543, 223, 629, 372, 364, 332, 219, 387, 399, 1879, 306, 469, 73, 634, 361, 269, 301, 1012, 347, 301, 351, 493, 68, 360, 44, 506, 274, 256, 79, 391, 374, 1986, 324, 280, 398, 499, 91, 188, 1229, 1085, 695, 386, 242, 555, 344, 770, 120, 446, 232, 315, 1245, 442, 757, 1034, 415, 249, 432, 1458, 396, 307, 308, 483, 324, 711, 530, 348, 286, 243, 438, 2118, 350, 2048, 55, 260, 952, 1154, 47, 803, 546, 55, 443, 368, 140, 776, 457, 514, 1128, 211, 532, 334, 650, 1134, 993, 456, 1125, 652, 322, 237, 457, 347, 355, 315, 514, 337, 310, 1075, 432, 689, 319, 329, 345, 2178, 2118, 1209, 400, 2122, 448, 1686, 775, 2100, 268, 429, 309, 201, 1143, 1249, 261, 88, 841, 286, 1855, 962, 297, 375, 402, 307, 1156, 415, 416, 282, 395, 571, 1587, 345, 524, 715, 661, 848, 923, 469, 1267, 1102, 667, 257, 308, 1220, 475, 398, 817, 394, 1145, 890, 244, 332, 561, 3608, 414, 184, 839, 65, 817, 541, 314, 1476, 544, 221, 1741, 1315, 349, 461, 239, 596, 69, 396, 582, 623, 319, 524, 180, 97, 201, 357, 657, 452, 283, 398, 143, 899, 311, 212, 244, 369, 251, 221, 359, 2424, 692, 84, 277, 1413, 515, 278, 633, 745, 407, 319, 329, 800, 755, 323, 77, 4253, 1128, 424, 877, 678, 57, 295, 817, 413, 591, 139, 387, 1610, 374, 540, 580, 332, 63, 308, 471, 394, 1032, 265, 122, 436, 278, 1118, 1001, 278, 255, 373, 486, 750, 206, 693, 1201, 787, 1633, 87, 311, 564, 460, 716, 449, 471, 763, 894, 51, 1614, 354, 2074, 988, 1354, 1324, 497, 701, 249, 2423, 568, 827, 570, 440, 299, 256, 406, 267, 1357, 961, 256, 1020, 540, 927, 653, 267, 1131, 540, 779, 243, 234, 1362, 253, 379, 1610, 1620, 1756, 296, 2549, 362, 1599, 379, 1034, 1668, 354, 64, 314, 255, 256, 184, 1431, 233, 1824, 1574, 178, 315, 386, 155, 447, 496, 613, 313, 267, 367, 311, 2293, 304, 488, 1801, 633, 366, 132, 256, 278, 1042, 359, 356, 191, 389, 1369, 247, 62, 444, 246, 4188, 471, 398, 671, 1063, 88, 2068, 452, 293, 83, 298, 531, 563, 292, 2402, 1207, 998, 272, 808, 307, 160, 876, 522, 346, 710, 290, 269, 532, 494, 707, 930, 659, 1857, 150, 360, 351, 109, 2248, 201, 552, 394, 1662, 254, 169, 97, 305, 579, 409, 228, 320, 1802, 2608, 428, 409, 1776, 429, 582, 343, 158, 585, 124, 1219, 945, 1874, 909, 258, 218, 770, 2182, 895, 776, 370, 281, 268, 174, 548, 522, 614, 372, 2444, 261, 841, 2591, 104, 297, 707, 153, 681, 5144, 240, 235, 1365, 420, 361, 466, 308, 459, 693, 1884, 323, 245, 1104, 429, 1273, 1999, 1478, 906, 173, 833, 1511, 1531, 1020, 91, 108, 1619, 470, 3896, 524, 1735, 384, 590, 232, 60, 478, 223, 231, 1995, 408, 317, 259, 232, 398, 654, 371, 439, 2149, 337, 487, 2987, 863, 723, 469, 50, 440, 257, 2341, 509, 220, 273, 287, 341, 2523, 1343, 362, 253, 578, 1632, 122, 708, 3178, 361, 760, 3058, 1005, 347, 48, 464, 303, 497, 341, 252, 2477, 908, 618, 2845, 421, 681, 326, 243, 277, 179, 315, 1776, 1457, 870, 1018, 1208, 403, 1702, 425, 584, 1198, 433, 326, 715, 556, 216, 77, 1456, 108, 292, 195, 345, 330, 604, 576, 2118, 797, 636, 297, 453, 377, 64, 359, 216, 1965, 326, 1012, 359, 1015, 3298, 273, 108, 297, 1720, 391, 259, 601, 669, 476, 2329, 768, 526, 379, 549, 256, 1004, 2210, 161, 1089, 332, 1375, 372, 318, 266, 1139, 1414, 279, 262, 601, 388, 360, 340, 2186, 1363, 305, 427, 1381, 525, 125, 399, 192, 76, 1929, 289, 254, 69, 388, 792, 546, 1841, 648, 427, 169, 255, 409, 745, 53, 1178, 443, 240, 580, 588, 665, 336, 282, 607, 1354, 331, 627, 211, 372, 326, 214, 296, 253, 620, 1251, 363, 877, 61, 337, 1000, 496, 410, 1761, 611, 417, 230, 305, 614, 298, 2533, 420, 1453, 765, 482, 341, 2506, 127, 794, 495, 285, 535, 343, 1498, 752, 185, 365, 467, 75, 384, 70, 609, 331, 401, 449, 2108, 297, 393, 808, 443, 149, 397, 984, 651, 693, 1404, 267, 352, 2053, 150, 502, 554, 339, 2969, 89, 563, 768, 654, 412, 553, 756, 435, 4236, 200, 603, 840, 375, 723, 3014, 1108, 286, 355, 303, 315, 728, 713, 1617, 383, 346, 455, 308, 481, 286, 297, 374, 331, 538, 2768, 1595, 203, 367, 417, 1131, 408, 348, 561, 219, 273, 73, 1267, 250, 598, 430, 365, 372, 1284, 2646, 1070, 1504, 319, 281, 448, 463, 266, 336, 389, 954, 1066, 258, 2306, 618, 442, 3885, 320, 1571, 243, 304, 668, 1266, 672, 310, 123, 1077, 254, 323, 327, 74, 350, 59, 1082, 666, 1444, 247, 57, 365, 434, 358, 482, 337, 378, 421, 697, 1259, 2063, 250, 1845, 240, 465, 422, 568, 2000, 407, 316, 340, 1182, 354, 271, 2244, 358, 581, 264, 325, 521, 1292, 262, 335, 269, 369, 1184, 755, 59, 409, 680, 401, 343, 226, 1023, 291, 1016, 606, 844, 1447, 1806, 507, 200, 317, 373, 330, 372, 825, 1693, 232, 817, 353, 1065, 1639, 399, 551, 322, 294, 304, 808, 629, 1267, 277, 228, 1119, 365, 250, 410, 864, 1694, 1292, 1054, 1286, 210, 714, 892, 2654, 568, 801, 314, 731, 285, 298, 369, 374, 726, 316, 251, 1533, 197, 115, 245, 1004, 312, 615, 1033, 442, 1327, 1413, 309, 1707, 730, 842, 362, 979, 284, 81, 530, 510, 365, 619, 534, 3399, 947, 347, 364, 706, 337, 320, 323, 591, 227, 447, 791, 1152, 55, 850, 2179, 234, 320, 1707, 196, 460, 304, 249, 356, 297, 309, 869, 61, 483, 447, 977, 788, 1823, 1180, 241, 183, 3716, 1540, 237, 1028, 914, 327, 418, 334, 1510, 326, 116, 425, 131, 77, 61, 319, 66, 375, 289, 406, 2250, 492, 892, 503, 230, 1372, 474, 1571, 796, 431, 452, 286, 424, 2046, 203, 868, 572, 1825, 421, 474, 401, 54, 317, 1099, 1091, 617, 415, 1309, 509, 458, 373, 267, 986, 275, 2175, 1613, 314, 342, 804, 956, 1062, 255, 236, 142, 345, 362, 2548, 387, 314, 774, 307, 173, 457, 305, 114, 2139, 81, 433, 304, 6054, 1506, 604, 110, 675, 1013, 640, 271, 1756, 298, 361, 1370, 399, 1270, 428, 580, 476, 5286, 917, 594, 397, 618, 288, 305, 354, 1074, 1218, 311, 331, 976, 259, 2502, 958, 253, 755, 391, 1049, 244, 463, 281, 1013, 1049, 430, 230, 863, 1044, 1171, 1165, 59, 2713, 328, 1455, 293, 353, 3104, 389, 325, 994, 829, 255, 281, 2104, 43, 335, 858, 244, 933, 321, 1591, 677, 422, 448, 4209, 820, 331, 242, 368, 1755, 2326, 457, 325, 525, 491, 687, 1050, 519, 64, 876, 293, 142, 318, 268, 533, 402, 353, 368, 204, 500, 280, 254, 902, 763, 1359, 369, 310, 54, 2540, 319, 1529, 1140, 365, 918, 266, 405, 308, 1456, 169, 340, 344, 949, 1940, 881, 164, 345, 321, 1446, 562, 1210, 79, 269, 910, 473, 248, 1087, 1817, 335, 325, 414, 158, 822, 145, 288, 446, 886, 1743, 3023, 96, 1545, 310, 799, 247, 348, 753, 289, 207, 265, 411, 463, 2105, 275, 1133, 456, 263, 112, 326, 266, 355, 247, 616, 1399, 299, 410, 273, 1012, 305, 234, 399, 1339, 905, 679, 254, 221, 324, 233, 1495, 116, 341, 326, 2590, 277, 293, 1221, 438, 463, 274, 329, 149, 1684, 306, 146, 1472, 1778, 1443, 261, 2651, 260, 448, 448, 265, 54, 405, 424, 897, 332, 1903, 594, 1484, 80, 823, 561, 392, 651, 62, 1142, 318, 351, 243, 380, 658, 2501, 337, 792, 63, 377, 381, 233, 362, 482, 300, 262, 740, 350, 745, 264, 394, 588, 451, 595, 388, 341, 76, 384, 596, 249, 619, 1123, 6525, 160, 1622, 420, 1527, 506, 1254, 729, 304, 395, 376, 1148, 781, 298, 73, 236, 301, 4801, 1917, 308, 281, 551, 540, 950, 121, 355, 68, 884, 307, 1106, 263, 644, 378, 272, 280, 1211, 4585, 967, 1893, 342, 470, 1429, 565, 861, 171, 124, 395, 79, 332, 376, 309, 289, 1561, 613, 458, 497, 369, 595, 245, 623, 387, 392, 377, 120, 240, 444, 316, 250, 499, 275, 435, 386, 233, 994, 326, 328, 405, 794, 322, 1185, 301, 154, 411, 298, 1251, 536, 546, 597, 1544, 2739, 264, 330, 778, 280, 56, 1519, 248, 70, 330, 416, 363, 345, 1689, 260, 114, 306, 399, 73, 351, 397, 428, 438, 339, 56, 1010, 1034, 369, 877, 57, 325, 814, 1645, 271, 363, 382, 987, 219, 309, 454, 553, 261, 270, 1173, 53, 233, 710, 883, 2508, 1454, 317, 300, 286, 705, 427, 222, 494, 1598, 611, 894, 494, 307, 1114, 223, 1817, 301, 493, 267, 318, 811, 214, 302, 323, 417, 210, 139, 1622, 59, 226, 410, 576, 369, 581, 361, 1407, 101, 734, 1367, 484, 314, 415, 349, 321, 498, 368, 205, 308, 438, 379, 335, 509, 638, 488, 391, 281, 369, 2553, 201, 442, 607, 1093, 616, 608, 266, 357, 245, 996, 1039, 257, 342, 830, 540, 324, 150, 951, 423, 340, 303, 1008, 1926, 1207, 207, 267, 626, 479, 757, 349, 502, 363, 629, 1737, 737, 571, 961, 825, 489, 523, 1345, 658, 303, 580, 389, 1442, 685, 444, 351, 938, 652, 368, 663, 2141, 499, 238, 762, 236, 111, 408, 444, 432, 1793, 637, 782, 356, 340, 259, 3514, 2020, 2108, 296, 1197, 606, 154, 94, 255, 289, 1091, 79, 303, 442, 400, 355, 280, 267, 1333, 770, 370, 143, 336, 311, 331, 236, 2156, 994, 604, 558, 337, 234, 1467, 6287, 344, 1464, 559, 265, 1024, 4228, 680, 459, 1711, 202, 449, 2531, 304, 354, 866, 611, 600, 351, 2983, 1465, 560, 240, 224, 605, 372, 565, 478, 368, 207, 819, 494, 723, 1045, 248, 328, 322, 489, 270, 76, 5408, 372, 71, 341, 2599, 1568, 294, 491, 129, 219, 2867, 590, 1744, 464, 1132, 263, 415, 1443, 295, 358, 338, 223, 1228, 1042, 3733, 795, 586, 583, 313, 263, 406, 1027, 933, 1628, 344, 306, 503, 264, 992, 343, 402, 35, 598, 124, 1175, 389, 952, 286, 270, 1161, 273, 591, 1400, 544, 896, 386, 609, 774, 2880, 384, 377, 273, 489, 733, 1962, 1144, 682, 1393, 1878, 851, 771, 340, 333, 312, 1231, 407, 394, 327, 1303, 347, 236, 424, 47, 309, 765, 381, 561, 1145, 60, 267, 266, 1302, 848, 711, 512, 1394, 613, 99, 518, 542, 68, 366, 3186, 338, 1488, 852, 1726, 253, 326, 326, 1507, 314, 802, 336, 330, 243, 265, 2301, 387, 62, 316, 409, 413, 379, 708, 835, 1311, 302, 290, 64, 412, 347, 289, 841, 1293, 255, 305, 337, 405, 478, 436, 489, 224, 301, 557, 299, 72, 275, 1126, 225, 400]}],\n",
              "                        {\"bargap\": 0.2, \"bargroupgap\": 0.2, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of word counts within comments\"}, \"xaxis\": {\"title\": {\"text\": \"Word Count\"}}, \"yaxis\": {\"title\": {\"text\": \"Frequency\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b1d71f95-7255-428d-bca9-419a46b0a3b1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_kpqbtuK7GX",
        "outputId": "a594ee8f-d313-428a-b772-0faaa8846c5f"
      },
      "source": [
        "minlim, maxlim = 50, 1e4\n",
        "# remove comments with the length of fewer than 50 words\n",
        "print('size of the data before remove: ', len(train_df))\n",
        "train_df['words_len'] = train_df['words_len'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else None)\n",
        "train_df = train_df.dropna(subset=['words_len'])\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "print('size of the data after remove: ', len(train_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of the data before remove:  6896\n",
            "size of the data after remove:  6865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOMRXTeVE8zz"
      },
      "source": [
        "### Distribution of Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "y2LkjHz5Eto7",
        "outputId": "acda6bc2-b816-4b92-e7e9-40175af03ae0"
      },
      "source": [
        "fig = go.Figure()\n",
        "topic_freq = train_df.label_id.value_counts()\n",
        "fig.add_trace(go.Bar(y=topic_freq, x=topic_freq.index.to_numpy()))\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of each class',\n",
        "    xaxis_title_text='classes',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"f2da18d0-be39-4155-b7fd-63beafc1b10a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"f2da18d0-be39-4155-b7fd-63beafc1b10a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'f2da18d0-be39-4155-b7fd-63beafc1b10a',\n",
              "                        [{\"type\": \"bar\", \"x\": [3, 0, 5, 2, 6, 1, 4], \"y\": [2245, 1575, 1342, 1299, 206, 101, 97]}],\n",
              "                        {\"bargap\": 0.2, \"bargroupgap\": 0.2, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of each class\"}, \"xaxis\": {\"title\": {\"text\": \"classes\"}}, \"yaxis\": {\"title\": {\"text\": \"Frequency\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f2da18d0-be39-4155-b7fd-63beafc1b10a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZZKiLfSNS2I"
      },
      "source": [
        "## Prepare data for Albert-LM\n",
        "  - using transformers tokenizer\n",
        "  - tiny and fast BERT-ish Language Model (just 70MB)\n",
        "    - the pre-trained model is from [Merhdad Farhani](https://github.com/m3hrdadfi/albert-persian)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2s1ERBqkMLp"
      },
      "source": [
        "- this is the latest version from official repository\n",
        "- the new version removes half-space and newlines in its tokenizer (you don't have to handle it in your cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezhttJizVUvC"
      },
      "source": [
        "batch_size = 16\n",
        "max_len = 256\n",
        "class_number = 7\n",
        "# this is the latest version from official repository\n",
        "model_name = \"HooshvareLab/albert-fa-zwnj-base-v2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR_6Q7fBM5U8"
      },
      "source": [
        "from transformers import AlbertTokenizerFast\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QnRbDOAoxsJ"
      },
      "source": [
        "- Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hkAQQCzOJUX",
        "outputId": "a386b68c-7a32-4e5b-d299-7bc22a4e37e9"
      },
      "source": [
        "train_encodings = tokenizer(train_df.cleaned.tolist(), max_length=max_len, truncation=True, padding=True)\n",
        "print('train tokenized')\n",
        "test_encodings = tokenizer(test_df.cleaned.tolist(), max_length=max_len, truncation=True, padding=True)\n",
        "print('test tokenized')\n",
        "valid_encodings = tokenizer(eval_df.cleaned.tolist(), max_length=max_len, truncation=True, padding=True)\n",
        "print('valid tokenized')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train tokenized\n",
            "test tokenized\n",
            "valid tokenized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3afpqniQQaKj"
      },
      "source": [
        "- create config for our classification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "54cec73d094547bbacd4815d4c00df42",
            "e50f4dcd25eb434391e9ede8fc0c413d",
            "d316adf9ebe44588911978aeadf99da4",
            "498b3e9c437e4dde8b75e6d85d01a545",
            "ea3c09d1c63c47b68a7b7f26902b84ce",
            "8092f8184aea440692882c11a286f2ae",
            "58a70ab48c7d424eb7f78cadcc159e62",
            "3b841ecf971a4cb6879401e1d0b54865"
          ]
        },
        "id": "8EpvLjTjP8se",
        "outputId": "00157c43-83d3-4887-d2e2-ee5a57d3659c"
      },
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "# create a dict for classes\n",
        "label2id = {label: i for i, label in enumerate(range(class_number))}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "config = AutoConfig.from_pretrained(model_name,**{'label2id': label2id, 'id2label': id2label})\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54cec73d094547bbacd4815d4c00df42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "label2id: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
            "id2label: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L2_R91zSUm7"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "567oD3NOS3YR"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPKLhYPJTDIw"
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AlbertForSequenceClassification\n",
        "# set device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Q_5nRLS5PC"
      },
      "source": [
        "class DigiMagDs(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# create datasets\n",
        "train_ds = DigiMagDs(train_encodings, train_df.label_id)\n",
        "valid_ds = DigiMagDs(valid_encodings, eval_df.label_id)\n",
        "test_ds = DigiMagDs(test_encodings, test_df.label_id)\n",
        "\n",
        "# create Dataloders\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu0lThFXUcwJ"
      },
      "source": [
        "- My PyTorch Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_RdgHdMb28_"
      },
      "source": [
        "import time, sys\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class TorchTrainer:\n",
        "    def __init__(self, model, train_dl, valid_dl, optimizer):\n",
        "        self.model = model\n",
        "        self.train_dl = train_dl\n",
        "        self.valid_dl = valid_dl\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_history = []\n",
        "\n",
        "    def fit(self, num_epochs):\n",
        "        clear_output()\n",
        "        valid_acc = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch %2d/%2d' % (epoch + 1, num_epochs))\n",
        "            print('-' * 20)\n",
        "            t0 = time.time()\n",
        "            train_acc = self.train_model()\n",
        "            valid_acc = self.valid_model()\n",
        "            time_elapsed = time.time() - t0\n",
        "            print('\\n Metrics: | train_acc: %.3f | valid_acc: %.3f |' % (train_acc[0], valid_acc[0]))\n",
        "            print('\\n  Epoch complete in: %.0fm %.0fs \\n' % (time_elapsed // 60, time_elapsed % 60))\n",
        "        return\n",
        "\n",
        "    def train_model(self):\n",
        "        self.model.train()\n",
        "        N = len(self.train_dl.dataset)\n",
        "        step = N // self.train_dl.batch_size\n",
        "        avg_loss = 0.0\n",
        "        avg_acc = 0.0\n",
        "        for i, batch in enumerate(self.train_dl):\n",
        "            self.optimizer.zero_grad()\n",
        "            # forward\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            predictions = torch.argmax(outputs['logits'], dim=1)\n",
        "            # loss\n",
        "            loss = outputs['loss']\n",
        "            # backward\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            # statistics of model training and print\n",
        "            avg_loss = (avg_loss * i + loss) / (i + 1)\n",
        "            avg_acc += torch.sum(predictions == labels)\n",
        "            self.loss_history.append(avg_loss)\n",
        "            sys.stdout.flush()\n",
        "            sys.stdout.write(\"\\r  Train_Step: %d/%d | runing_loss: %.4f\" % (i + 1, step, avg_loss))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "        return torch.tensor([avg_acc]) / N\n",
        "\n",
        "    def valid_model(self):\n",
        "        print()\n",
        "        self.model.eval()\n",
        "        N = len(self.valid_dl.dataset)\n",
        "        step = N // self.valid_dl.batch_size\n",
        "        avg_loss = 0.0\n",
        "        avg_acc = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.valid_dl):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                predictions = torch.argmax(outputs['logits'], dim=1)\n",
        "                loss = outputs['loss']\n",
        "                avg_loss = (avg_loss * i + loss) / (i + 1)\n",
        "                avg_acc += torch.sum(predictions == labels)\n",
        "                sys.stdout.flush()\n",
        "                sys.stdout.write(\"\\r  Valid_Step: %d/%d | runing_loss: %.4f\" % (i, step, avg_loss))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "        return torch.tensor([avg_acc]) /N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDbCED5DcVU3",
        "outputId": "28819552-0961-410b-ca72-a95df08855fb"
      },
      "source": [
        "model = AlbertForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "model.to(device)\n",
        "# AdamW is just adam with fixing on weight decay (don't worry about it)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=0.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/albert-fa-zwnj-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/albert-fa-zwnj-base-v2 and are newly initialized: ['albert.pooler.weight', 'albert.pooler.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMWUGX9dvz2p",
        "outputId": "1afb321c-6d55-4751-e6d9-671fb1cb2194"
      },
      "source": [
        "trainer = TorchTrainer(model, train_dl, valid_dl, optimizer=optimizer)\n",
        "trainer.fit(num_epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1/ 2\n",
            "--------------------\n",
            "  Train_Step: 427/426 | runing_loss: 0.3749\n",
            "  Valid_Step: 47/47 | runing_loss: 0.2160\n",
            " Metrics: | train_acc: 0.893 | valid_acc: 0.941 |\n",
            "\n",
            "  Epoch complete in: 11m 4s \n",
            "\n",
            "Epoch  2/ 2\n",
            "--------------------\n",
            "  Train_Step: 427/426 | runing_loss: 0.2136\n",
            "  Valid_Step: 47/47 | runing_loss: 0.2005\n",
            " Metrics: | train_acc: 0.942 | valid_acc: 0.935 |\n",
            "\n",
            "  Epoch complete in: 10m 55s \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCiMbYyiTbCG"
      },
      "source": [
        "- We achieve 94% just in 2 epochs \n",
        "  - and without any hyperparameters optimization\n",
        "  - Not bad ha?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JVrPvmVVcYq"
      },
      "source": [
        "## Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-is8b3O5VZXi"
      },
      "source": [
        "from transformers import TFAlbertForSequenceClassification\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weQBWOTKSx1A"
      },
      "source": [
        "- creat tf_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NFO3vEdNJgQ",
        "outputId": "c3b146af-39c9-4bbb-e206-47ce6395990b"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_df.label_id))\n",
        "train_ds = train_ds.shuffle(1024).batch(batch_size, drop_remainder=True)\n",
        "print('train dataset created')\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_df.label_id))\n",
        "test_ds = test_ds.shuffle(512).batch(batch_size, drop_remainder=True)\n",
        "print('test dataset created')\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((dict(valid_encodings), eval_df.label_id))\n",
        "valid_ds = valid_ds.shuffle(512).batch(batch_size, drop_remainder=True)\n",
        "print('valid dataset created')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train dataset created\n",
            "test dataset created\n",
            "valid dataset created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnL7dGhW56U4"
      },
      "source": [
        "- the original model is based on PyTorch\n",
        "- If you need use Albert-Persian in TF you have to use `from_pt=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX98Ehc25Mlx",
        "outputId": "1b6a8cf3-4568-4f6e-d3fc-5ec1ab4541b8"
      },
      "source": [
        "# load model\n",
        "model = TFAlbertForSequenceClassification.from_pretrained(model_name, config=config, from_pt=True)\n",
        "# compile model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['acc']) # you can also use any keras loss fn\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_albert_for_sequence_classification_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "albert (TFAlbertMainLayer)   multiple                  11683584  \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  5383      \n",
            "=================================================================\n",
            "Total params: 11,688,967\n",
            "Trainable params: 11,688,967\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS7BQgBG5Vbx",
        "outputId": "ffb611fd-c305-411e-c64e-6439f154b219"
      },
      "source": [
        "H = model.fit(train_ds, validation_data=valid_ds, epochs=2, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "426/426 [==============================] - 920s 2s/step - loss: 0.5785 - acc: 0.8232 - val_loss: 0.2331 - val_acc: 0.9295\n",
            "Epoch 2/2\n",
            "426/426 [==============================] - 875s 2s/step - loss: 0.2243 - acc: 0.9400 - val_loss: 0.1981 - val_acc: 0.9348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JLRhfJNW7mO",
        "outputId": "a218a19f-ffab-494f-dee4-cd622b4c7a86"
      },
      "source": [
        "# get result on Test set\n",
        "metrics = model.evaluate(test_ds)\n",
        "print('test loss: ', metrics[0])\n",
        "print('test acc: ', metrics[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 30s 562ms/step - loss: 0.2437 - acc: 0.9387\n",
            "test loss:  0.2437356561422348\n",
            "test acc:  0.9386792182922363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMEyljvuS0oD"
      },
      "source": [
        "## How can we achieve better results\n",
        "- with hyper parameters tuning\n",
        "  - more epoch\n",
        "  - different batch size\n",
        "  - bigger max len \n",
        "  - ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQ5Jess2PpO"
      },
      "source": [
        "## HuggingFace 🤗\n",
        "- you can also train it with HuggingFace Trainer & TFTrainer\n",
        "- for more details see [this](https://huggingface.co/transformers/main_classes/trainer.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYdRw_6GShbB"
      },
      "source": [
        "# In The End\n",
        "- thanks for your attention\n",
        "- sorry, my English is not great but you can get the idea\n",
        "- write your comments and ideas below\n",
        "  - and say about my mistakes or ..."
      ]
    }
  ]
}