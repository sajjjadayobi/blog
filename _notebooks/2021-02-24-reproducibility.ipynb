{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_02_24_reproducibility.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzCBIpr-rTQN"
      },
      "source": [
        "# Reproducibility in Deep Learning\n",
        "> do you want to check your ideas in DL? you need Reproducibility (PyTorch, TF2.X)\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true,\n",
        "- comments: true\n",
        "- image: images/reproducibility.jpg\n",
        "- author: Sajjad Ayoubi\n",
        "- categories: [tips]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZdHd8iMgqi_"
      },
      "source": [
        "# Reproducibility ?!\n",
        "- deep learning training processes are stochastic in nature,\n",
        "During development of a model, sometimes it is useful to be able to obtain reproducible results from run to run in order to determine if a change in performance is due to an actual model or data modification, also for comparing different things and evaluate new tricks and ideas\n",
        "we need to train our neural nets in a deterministic way\n",
        "- In the process of training a neural network, there are multiple stages where randomness is used, for example\n",
        "\n",
        "  - random initialization of weights of the network before the training starts.\n",
        "  - regularization, dropout, which involves randomly dropping nodes in the network while training.\n",
        "  - optimization process like SGD or Adam also include random initializations.\n",
        "\n",
        "- we will see that how can we use Frameworks in a deterministic way\n",
        "- note in deterministic training you are a bit slow than stochastic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49O6wVwCg97n"
      },
      "source": [
        "# PyTorch\n",
        "- Mnist classification with Reproducibility\n",
        "> from PyTorch Team: Completely reproducible results are not guaranteed across PyTorch releases, individual commits, or different platforms. Furthermore, results may not be reproducible between CPU and GPU executions, even when using identical seeds, also Deterministic operations are often slower than nondeterministic operations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYYerlUHhJGE"
      },
      "source": [
        "- the following works with all models (maybe not LSTMs I didnâ€™t check that)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-0OKsP1hQZb"
      },
      "source": [
        "import numpy as np\n",
        "import random, os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6L4vLbyhjdC"
      },
      "source": [
        "- create dataloder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9bGuahjhh04"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0), (255))])\n",
        "train_ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# if you set augmentations set worker_init_fn=(random.seed(0)) and num_workers=0 in dataloder\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-E8uqh8qAwN"
      },
      "source": [
        "- the following works with all models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP0UPACHgrDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef42900-45b8-4f5a-e7da-6c2a93d40092"
      },
      "source": [
        "def torch_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0y62feKh4Le"
      },
      "source": [
        "def train(reproducibility=True, n_run=2, device='cuda'):\n",
        "    \n",
        "    for n in range(n_run):\n",
        "      print('run number: ', n+1)\n",
        "\n",
        "      # set seed before create your model  \n",
        "      if reproducibility:\n",
        "          torch_seed(seed=0)\n",
        "      # compile model\n",
        "      model = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 128), nn.GELU(), nn.Linear(128, 10)).to(device)\n",
        "      loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "      optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=0.0)\n",
        "      # training loop\n",
        "      loss_avg = 0.0\n",
        "      for i, data in enumerate(train_dl):\n",
        "          inputs, labels = data\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs.to(device))\n",
        "          loss = loss_fn(outputs, labels.to(device))\n",
        "          loss_avg = (loss_avg * i + loss) / (i+1)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if i%850==0:   \n",
        "              print('[%d, %4d] loss: %.4f' %(i+1, len(train_dl), loss_avg))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGL0ECThk9kC",
        "outputId": "facf5d17-ed74-4361-9b2b-af5af41380b6"
      },
      "source": [
        "train(reproducibility=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run number:  1\n",
            "[1, 1875] loss: 2.2943\n",
            "[851, 1875] loss: 0.8099\n",
            "[1701, 1875] loss: 0.5946\n",
            "run number:  2\n",
            "[1, 1875] loss: 2.2945\n",
            "[851, 1875] loss: 0.8078\n",
            "[1701, 1875] loss: 0.5921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IgPUFjhDI4v",
        "outputId": "1b19ad3c-d4cc-4bb7-93ca-13cfe63c602c"
      },
      "source": [
        "train(reproducibility=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run number:  1\n",
            "[1, 1875] loss: 2.2983\n",
            "[851, 1875] loss: 0.8051\n",
            "[1701, 1875] loss: 0.5927\n",
            "run number:  2\n",
            "[1, 1875] loss: 2.2983\n",
            "[851, 1875] loss: 0.8051\n",
            "[1701, 1875] loss: 0.5927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5qKzus5lHbS"
      },
      "source": [
        "- if you check your new ideas like me\n",
        "- you have to always see how much is overhead of your implementation\n",
        "- in pytorch for giving acutual time we use `synchronize`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfLOBO4akSNs"
      },
      "source": [
        "%%timeit\n",
        "# stay in GPUs until it done\n",
        "torch.cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8aho7jemC_0"
      },
      "source": [
        "# Keras & TF 2.X\n",
        "- Mnist classification with Reproducibility\n",
        "> from Keras Team: when running on a GPU, some operations have non-deterministic outputs, in particular tf.reduce_sum(). This is due to the fact that GPUs run many operations in parallel, so the order of execution is not always guaranteed. Due to the limited precision of floats, even adding several numbers together may give slightly different results depending on the order in which you add them. You can try to avoid the non-deterministic operations, but some may be created automatically by TensorFlow to compute the gradients, so it is much simpler to just run the code on the CPU. For this, you can set the CUDA_VISIBLE_DEVICES environment variable to an empty string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLKIcsWpmQ3S"
      },
      "source": [
        "- they said Keras REPRODUCIBILITY works just on CPUs\n",
        "- but we need GPUs\n",
        "- after a week seach I found a possible way on GPUs\n",
        "  - based on this work [TensorFlow Determinism](https://github.com/NVIDIA/framework-determinism) from `NVIDIA`\n",
        "  - now we can run Keras with REPRODUCIBILITY on GPUs :)\n",
        "\n",
        "- Note: it works just for `TF >= 2.3`\n",
        "  - also it works fine with `tf.data`\n",
        "  - but you have to watch out (especially prefetch) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFoemKoym4cs"
      },
      "source": [
        "- let's check this out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7qoRvHgmFi9"
      },
      "source": [
        "import random, os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VBPHh0TnahU",
        "outputId": "415f1d0b-3f86-4668-fce0-aa99af02e299"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyBxZI2aoW3Z"
      },
      "source": [
        "def tf_seed(seed=0):\n",
        "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\t# For working on GPUs from \"TensorFlow Determinism\"\n",
        "\tos.environ[\"TF_DETERMINISTIC_OPS\"] = str(seed)\n",
        "\tnp.random.seed(seed)\n",
        "\trandom.seed(seed)\n",
        "\ttf.random.set_seed(seed)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnJlJ4v0neW4"
      },
      "source": [
        "def train(reproducibility=True, n_run=2):\n",
        "    \n",
        "    for n in range(n_run):\n",
        "      print('run number: ', n+1)\n",
        "\n",
        "      # set seed before create your model  \n",
        "      if reproducibility:\n",
        "          tf_seed(seed=0)\n",
        "\n",
        "      # compile model\n",
        "      model = tf.keras.models.Sequential([Flatten(input_shape=(28, 28)), Dense(128, activation='gelu'), Dense(10)])\n",
        "      loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "      model.compile(optimizer='adam', loss=loss_fn)\n",
        "      # training \n",
        "      model.fit(x_train, y_train, epochs=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp9CBazSoqsr",
        "outputId": "d715595e-70e6-41d0-d186-3e6e79b16290"
      },
      "source": [
        "train(reproducibility=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run number:  1\n",
            "1875/1875 [==============================] - 4s 1ms/step - loss: 0.4279\n",
            "run number:  2\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpUj63J8otXz",
        "outputId": "6492d66e-80a9-4e58-f2d9-8d5f611392ae"
      },
      "source": [
        "train(reproducibility=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run number:  1\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4124\n",
            "run number:  2\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTDppqXUpURK"
      },
      "source": [
        "- if you want run it on CPUs see this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCqFyHnupaV5"
      },
      "source": [
        "def tf_seed(seed=0):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    # if your machine has GPUs use following to off it\n",
        "    os.environ['CUDA_VISBLE_DEVICE'] = ''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    python_random.seed(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
