{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5s_QlTwpJZY"
   },
   "source": [
    "# Introduction to Knowledge Distillation \n",
    "> whith two code examples\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- image: images/kd.png\n",
    "- comments: true\n",
    "- author: Sajjad Ayoubi\n",
    "- categories: [implementation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I found [this](https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Neural-Networks--VmlldzoyMjkxODk) article great for details in knowledge distillation\n",
    "- Soft lables [image](https://lh4.googleusercontent.com/ZoaRoo-dWpdIx7iCmbEICmFcOPJLuVC2fc_Pau6akiBbLG6ad-IczRXgKHhnMXDuCXJbmxRU8ucPUJXH18B-cLUTvWekxqQn3cJTaybv3RGK8_5U0lxL8ZOeT6UalyelYBFpxTiL)\n",
    "\n",
    "- Reference:\n",
    "  - [Hinton et al. (2015)](https://arxiv.org/abs/1503.02531)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ziI6ohv3hum"
   },
   "source": [
    "## My notes\n",
    "- a high-quality Teacher is important\n",
    "- feature map level distillation\n",
    "  - `DistilBERT`\n",
    "- the T and S can be anythings\n",
    "  - example: T is BERT, S is LSTM\n",
    "- with `aug` it has more gain\n",
    "  - because augmented data has no hard label\n",
    "  - with a huge T model we even don't need to have the same label `aug`\n",
    "  - it's kind of semi-supervised for S\n",
    "- soft labeling is really mater in `LMs`\n",
    "  - I have a cute [cat, dog, pet, ...] -> dark knowledge\n",
    "  - I have a cute [cat, tree, an, ...] -> one hot\n",
    "- `KD` in Online learning\n",
    "  - you have a small model in Server\n",
    "  - with a big Model for teaching with new data\n",
    "- `KD` help to regularizing `overfit` in neural networks\n",
    "  - Teacher learned generalization\n",
    "  - but don't use it just for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJbYXou6chZf",
    "outputId": "7caa39d6-3964-49db-df88-ba0ecbc2ae9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 23 14:48:23 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ND5-GmOHLdY"
   },
   "source": [
    "## Vision Example: Mnist Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t3GgbDYkAFFv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os , random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYK6cW6pAM49",
    "outputId": "621174d9-eeb9-4400-daa8-dc5fd22aabb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Prepare the train and test dataset.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1)).astype(\"float32\")\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2MRwqsjkQNE",
    "outputId": "f439c35a-bbd5-44ab-b6b9-e8d1213cf1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                15690     \n",
      "=================================================================\n",
      "Total params: 20,682\n",
      "Trainable params: 20,586\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "1875/1875 [==============================] - 38s 3ms/step - loss: 0.4718 - acc: 0.8510 - val_loss: 0.0876 - val_acc: 0.9749\n",
      "Epoch 2/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1137 - acc: 0.9645 - val_loss: 0.0631 - val_acc: 0.9796\n",
      "Epoch 3/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0914 - acc: 0.9711 - val_loss: 0.0487 - val_acc: 0.9838\n",
      "Epoch 4/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0799 - acc: 0.9753 - val_loss: 0.0472 - val_acc: 0.9844\n",
      "Epoch 5/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0681 - acc: 0.9785 - val_loss: 0.0497 - val_acc: 0.9844\n",
      "Epoch 6/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0624 - acc: 0.9801 - val_loss: 0.0416 - val_acc: 0.9863\n",
      "Epoch 7/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0624 - acc: 0.9806 - val_loss: 0.0437 - val_acc: 0.9858\n",
      "Epoch 8/8\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0557 - acc: 0.9824 - val_loss: 0.0379 - val_acc: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4441a28290>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "teacher.summary()\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "teacher.compile(optimizer=optim,\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['acc'])\n",
    "\n",
    "teacher.fit(x_train, y_train, epochs=8, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBEbwAPJZH31",
    "outputId": "cd75d71f-5b29-46f5-99e9-e2699fc6e130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"student\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                10990     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                150       \n",
      "=================================================================\n",
      "Total params: 11,140\n",
      "Trainable params: 11,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6094 - acc: 0.1999 - val_loss: 1.7388 - val_acc: 0.3541\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5936 - acc: 0.4178 - val_loss: 1.3059 - val_acc: 0.5489\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1982 - acc: 0.5602 - val_loss: 1.0485 - val_acc: 0.5982\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9959 - acc: 0.6132 - val_loss: 0.8854 - val_acc: 0.6836\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8133 - acc: 0.7029 - val_loss: 0.7248 - val_acc: 0.7487\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7247 - acc: 0.7540 - val_loss: 0.6509 - val_acc: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43ee0f6b50>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_student():\n",
    "    student = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(28, 28, 1)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(14, activation='relu'),\n",
    "            layers.Dense(10),\n",
    "        ],name=\"student\")\n",
    "    return student\n",
    "\n",
    "student = create_student()\n",
    "student.summary()\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "student.compile(optimizer=optim,\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['acc'])\n",
    "\n",
    "student.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0VXSfdSYUu-"
   },
   "source": [
    "- what is softmax temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLX3gY8xXTp4",
    "outputId": "d5ea78d7-9ca4-48aa-8ef4-ad45d482cf29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.97962921 0.01794253 0.00242826], shape=(3,), dtype=float64)\n",
      "tf.Tensor([0.71483081 0.18842736 0.09674183], shape=(3,), dtype=float64)\n",
      "tf.Tensor([0.57125779 0.25668267 0.17205954], shape=(3,), dtype=float64)\n",
      "tf.Tensor([0.45062671 0.30206411 0.24730918], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([9., 5., 3.])\n",
    "\n",
    "print(tf.nn.softmax(a))\n",
    "print(tf.nn.softmax(a/3))\n",
    "print(tf.nn.softmax(a/5))\n",
    "print(tf.nn.softmax(a/10))\n",
    "# T is not a HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "W9P5qXrqRjGu"
   },
   "outputs": [],
   "source": [
    "class DistillLeaner(keras.Model):\n",
    "\n",
    "    def __init__(self, student, teacher):\n",
    "        super(DistillLeaner, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(self, optimizer, metrics, student_loss_fn, distill_loss_fn, alpha=0.1):\n",
    "        super(DistillLeaner, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distill_loss_fn = distill_loss_fn\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        # Forward pass of teacher\n",
    "        teacher_logits = self.teacher(x, training=False)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_logits = self.student(x, training=True)\n",
    "            # CELoss on hard labels\n",
    "            student_loss = self.student_loss_fn(y, student_logits)\n",
    "            # distillation loss\n",
    "            distill_loss = self.distill_loss_fn(teacher_logits, student_logits)\n",
    "            # combine togather\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distill_loss\n",
    "\n",
    "        # Compute gradients & # Update weights\n",
    "        gradients = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n",
    "\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, student_logits)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss, \"distill_loss\": distill_loss})\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        logits = self.student(x, training=False)\n",
    "        # Calculate the loss & Update the metrics.\n",
    "        student_loss = self.student_loss_fn(y, logits)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OW-PLPJjRl6i"
   },
   "outputs": [],
   "source": [
    "def distill_loss_on_probs(teacher_logits, student_logits, loss_func=keras.losses.KLDivergence(), temp=3):\n",
    "    teacher_probs = tf.nn.softmax(teacher_logits / temp, axis=1)\n",
    "    student_logits = tf.nn.softmax(student_logits / temp, axis=1)\n",
    "    loss = loss_func(teacher_probs, student_logits) * temp**2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWCEQETXQJgv",
    "outputId": "02c80618-a468-489f-d523-24d08e48757b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.3409 - student_loss: 2.2838 - distill_loss: 11.6732 - val_acc: 0.5336 - val_student_loss: 0.9119\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.6224 - student_loss: 0.9106 - distill_loss: 6.0831 - val_acc: 0.8649 - val_student_loss: 0.7081\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8674 - student_loss: 0.5287 - distill_loss: 2.5995 - val_acc: 0.8925 - val_student_loss: 0.0706\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8882 - student_loss: 0.4622 - distill_loss: 2.2731 - val_acc: 0.8834 - val_student_loss: 0.0381\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8914 - student_loss: 0.4507 - distill_loss: 2.2082 - val_acc: 0.8899 - val_student_loss: 0.1761\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.8967 - student_loss: 0.4366 - distill_loss: 2.1420 - val_acc: 0.8942 - val_student_loss: 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43e66883d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distiller = DistillLeaner(student=create_student(), teacher=teacher)\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "distiller.compile(\n",
    "    optimizer=optim, metrics=['acc'], alpha=0.5, # alpcha depends on Teacher quality\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distill_loss_fn=lambda x, y: distill_loss_on_probs(x, y, loss_func=keras.losses.KLDivergence(), temp=3),\n",
    ")\n",
    "\n",
    "distiller.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKj3BApAaspz"
   },
   "source": [
    "### Alpha & Temp\n",
    "\n",
    "- good temp is range 1 to 5\n",
    "- train without smooting labels\n",
    "  - temp=1 regural softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UI-5sgc4JNft",
    "outputId": "bf25407e-b1c7-4885-d4eb-b69eb9b18180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.2859 - student_loss: 2.1936 - distill_loss: 1.7353 - val_acc: 0.5280 - val_student_loss: 0.9626\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.5262 - student_loss: 1.2288 - distill_loss: 1.1484 - val_acc: 0.5785 - val_student_loss: 0.8914\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.6132 - student_loss: 0.9515 - distill_loss: 0.8945 - val_acc: 0.7095 - val_student_loss: 0.4716\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.7398 - student_loss: 0.7168 - distill_loss: 0.6630 - val_acc: 0.8145 - val_student_loss: 0.5897\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8234 - student_loss: 0.5569 - distill_loss: 0.5128 - val_acc: 0.8512 - val_student_loss: 0.2171\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8576 - student_loss: 0.4812 - distill_loss: 0.4433 - val_acc: 0.8633 - val_student_loss: 0.4472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43e636d790>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distiller = DistillLeaner(student=create_student(), teacher=teacher)\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "distiller.compile(\n",
    "    optimizer=optim, metrics=['acc'], alpha=0.5, # alpcha depends on Teacher quality\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distill_loss_fn=lambda x, y: distill_loss_on_probs(x, y, loss_func=keras.losses.KLDivergence(), temp=1),\n",
    ")\n",
    "# the effect of TEMP\n",
    "distiller.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlmQc8htIk1w"
   },
   "source": [
    "- train just with soft-teacher-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eeI8g_gIYM4",
    "outputId": "7a1794ad-a285-42b6-922d-d4bbe8f35e80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.3481 - student_loss: 2.7879 - distill_loss: 11.4505 - val_acc: 0.7488 - val_student_loss: 0.9149\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.7764 - student_loss: 0.6838 - distill_loss: 3.5558 - val_acc: 0.8822 - val_student_loss: 0.0873\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8856 - student_loss: 0.4590 - distill_loss: 2.1813 - val_acc: 0.8943 - val_student_loss: 0.3185\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8990 - student_loss: 0.4224 - distill_loss: 1.9759 - val_acc: 0.9022 - val_student_loss: 0.0621\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.9040 - student_loss: 0.4136 - distill_loss: 1.9242 - val_acc: 0.9023 - val_student_loss: 0.3587\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.9042 - student_loss: 0.4031 - distill_loss: 1.8885 - val_acc: 0.9033 - val_student_loss: 0.2638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43da269150>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distiller = DistillLeaner(student=create_student(), teacher=teacher)\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "distiller.compile(\n",
    "    optimizer=optim, metrics=['acc'], alpha=0.0, # hard labels are off\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distill_loss_fn=lambda x, y: distill_loss_on_probs(x, y, loss_func=keras.losses.KLDivergence(), temp=3),\n",
    ")\n",
    "\n",
    "distiller.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l552FdyZ08r2"
   },
   "source": [
    "- Teacher Annealing Alpha from 0 to 1\n",
    "  - in earlier just look at the T then just Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gI4e05gGgZSo"
   },
   "outputs": [],
   "source": [
    "class TeacherAnnaling(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super(TeacherAnnaling, self).__init__()\n",
    "        self.epochs = epochs\n",
    "  \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.alpha += 1/self.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyqDhto2ouNK",
    "outputId": "be7c2f7b-3a18-43eb-b466-190c21f215b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.4803 - student_loss: 3.1257 - distill_loss: 10.1510 - val_acc: 0.8081 - val_student_loss: 0.6410\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8308 - student_loss: 0.6133 - distill_loss: 3.3149 - val_acc: 0.8937 - val_student_loss: 0.0219\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.8961 - student_loss: 0.4369 - distill_loss: 2.0684 - val_acc: 0.9070 - val_student_loss: 0.0320\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - acc: 0.9041 - student_loss: 0.3980 - distill_loss: 1.8594 - val_acc: 0.9054 - val_student_loss: 0.0431\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.9108 - student_loss: 0.3774 - distill_loss: 1.7609 - val_acc: 0.9092 - val_student_loss: 0.0115\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - acc: 0.9131 - student_loss: 0.3668 - distill_loss: 1.7028 - val_acc: 0.9109 - val_student_loss: 0.0230\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "distiller = DistillLeaner(student=create_student(), teacher=teacher)\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "distiller.compile(\n",
    "    optimizer=optim, metrics=['acc'], alpha=0.0, # alpcha depends on Teacher quality\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distill_loss_fn=lambda x, y: distill_loss_on_probs(x, y, loss_func=keras.losses.KLDivergence(), temp=3), # temps is not a hyper\n",
    ")\n",
    "# with CategoricalCrossentropy or MSE\n",
    "ta = TeacherAnnaling(epochs=6) # [from 0.0 to 1.0 step 0.2] \n",
    "distiller.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test), callbacks=[ta])\n",
    "print(distiller.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmpJBdFMfxI4"
   },
   "source": [
    "## NLP Example: IMDB classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZ8_hoyzf6gn",
    "outputId": "818c8b5c-0209-4f01-eb6e-06682439f202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 2.2MB 9.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 870kB 49.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.3MB 52.5MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 194kB 8.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 245kB 16.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 112kB 17.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.2MB 8.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPcW2Jz6g7yi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AlbertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpQwVZDEhboD"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'textattack/albert-base-v2-imdb'\n",
    "max_length = 64\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "lr = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z710wjG6hYJn"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BizXuI4bMIaS"
   },
   "outputs": [],
   "source": [
    "train, test = load_dataset('imdb', split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS992VNJhNiQ"
   },
   "outputs": [],
   "source": [
    "toknize_with_padding = lambda x: tokenizer(x['text'], truncation=True, padding=True, max_length=64) # bad model \n",
    "# prepare datasets\n",
    "train_ds = train.map(toknize_with_padding, batched=True, batch_size=128).shuffle()\n",
    "test_ds = test.map(toknize_with_padding, batched=True, batch_size=128).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XBS_yQeJGrN"
   },
   "outputs": [],
   "source": [
    "n_sample = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdZZQycsSSrB",
    "outputId": "3531f659-fd40-42ad-cd4e-4e08d0a2a1f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77       496\n",
      "           1       0.75      0.89      0.81       504\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.81      0.79      0.79      1000\n",
      "weighted avg       0.80      0.79      0.79      1000\n",
      "\n",
      "CPU times: user 2.28 s, sys: 983 ms, total: 3.27 s\n",
      "Wall time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(train_ds[:n_sample]['text'])\n",
    "y_train = np.array(train_ds[:n_sample]['label'])\n",
    "\n",
    "x_test = np.array(test_ds[:n_sample]['text'])\n",
    "y_test = np.array(test_ds[:n_sample]['label'])\n",
    "\n",
    "student = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression()) # CountVectorizer\n",
    "student.fit(x_train, y_train)\n",
    "print('model trained')\n",
    "\n",
    "y_pred = student.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "a6ec4fc1ba4e471f82c20375d8efe464",
      "9911d21048c94954a63b24b95e4b4ca8",
      "95999a0542da455a9043b5233dad6b34",
      "8c307cd28fa04768b5d6b48e852e1dc8",
      "8700b639919f4dff9e08819ce087997d",
      "5770ed73217e40eb84247a3f1ecf34ec",
      "6a787dbd6b8a4d4d89971eae9194af1b",
      "a02de1b5e59d4140b17f2ee681583207"
     ]
    },
    "id": "-7BjesD6pEt8",
    "outputId": "ee9b3cce-08c0-481c-bf7c-90f83b0cae67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ec4fc1ba4e471f82c20375d8efe464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=46747112.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "teacher = AlbertForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "teacher.eval().cuda()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2eo1pZEx5xu",
    "outputId": "52ae0656-7867-499d-993f-aa515d26ee07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85       496\n",
      "           1       0.83      0.88      0.86       504\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attention_mask = torch.tensor(test_ds['attention_mask'][:n_sample]).cuda()\n",
    "input_ids = torch.tensor(test_ds['input_ids'][:n_sample]).cuda()\n",
    "labels = torch.tensor(test_ds['label'][:n_sample]).cuda()\n",
    "\n",
    "test_teacher_logits = []\n",
    "batch_size = 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, n_sample-batch_size+1, batch_size):\n",
    "        test_teacher_logits.extend(teacher.forward(input_ids=input_ids[i:i+batch_size], \n",
    "                                              attention_mask=attention_mask[i:i+batch_size], \n",
    "                                              labels=labels[i:i+batch_size])['logits'].cpu().numpy())\n",
    "        \n",
    "test_teacher_logits = np.array(test_teacher_logits)\n",
    "y_pred = test_teacher_logits.argmax(axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "bGqHMRR11ZKC",
    "outputId": "01c80cc0-b35f-4136-b8a8-1ff6888d093a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       472\n",
      "           1       0.87      0.91      0.89       528\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.89      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_mask = torch.tensor(train_ds['attention_mask'][:n_sample]).cuda()\n",
    "input_ids = torch.tensor(train_ds['input_ids'][:n_sample]).cuda()\n",
    "labels = torch.tensor(train_ds['label'][:n_sample]).cuda()\n",
    "\n",
    "teacher_logits = []\n",
    "batch_size = 100\n",
    "with torch.no_grad():\n",
    "    for i in range(0, n_sample-batch_size+1, batch_size):\n",
    "        teacher_logits.extend(teacher.forward(input_ids=input_ids[i:i+batch_size], \n",
    "                                              attention_mask=attention_mask[i:i+batch_size], \n",
    "                                              labels=labels[i:i+batch_size])['logits'].cpu().numpy())\n",
    "        \n",
    "teacher_logits = np.array(teacher_logits)\n",
    "y_pred = teacher_logits.argmax(axis=1)\n",
    "print(classification_report(y_train, y_pred))\n",
    "plt.hist(teacher_logits);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beeITRDmSn2N"
   },
   "source": [
    "- using logist we don't need temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_XtvPOV5ttX",
    "outputId": "4ace2770-0385-419b-e57e-bcf3b9b0fc89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       496\n",
      "           1       0.79      0.88      0.83       504\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.83      0.82      0.82      1000\n",
      "weighted avg       0.83      0.82      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LinearRegression())\n",
    "student.fit(x_train, teacher_logits)\n",
    "\n",
    "y_pred = student.predict(x_test)\n",
    "print(classification_report(y_test, y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaEdCwyGzYSm"
   },
   "source": [
    "### Overfitted Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXp5Pvu3zuQs"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivG3nivwzXtw"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"result\",\n",
    "    evaluation_strategy='epoch',\n",
    "    save_steps=999999, # we don't need saving \n",
    "    learning_rate=8e-6,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "g9QsUi80ztTo",
    "outputId": "74b35e69-1774-4a44-a66d-52ec2187724d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 00:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.139151</td>\n",
       "      <td>2.438800</td>\n",
       "      <td>410.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.090243</td>\n",
       "      <td>2.437100</td>\n",
       "      <td>410.324000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End\n"
     ]
    }
   ],
   "source": [
    "teacher = AlbertForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=teacher,\n",
    "    args=args,\n",
    "    train_dataset=train_ds.select(range(1000)),\n",
    "    eval_dataset=train_ds.select(range(1000)))\n",
    "\n",
    "trainer.train()\n",
    "teacher.eval().cuda()\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "Y_37r01b4hf5",
    "outputId": "8e1b5a3a-aa13-4792-ff45-18f207017f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       472\n",
      "           1       0.97      0.98      0.97       528\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_mask = torch.tensor(train_ds['attention_mask'][:n_sample]).cuda()\n",
    "input_ids = torch.tensor(train_ds['input_ids'][:n_sample]).cuda()\n",
    "labels = torch.tensor(train_ds['label'][:n_sample]).cuda()\n",
    "\n",
    "teacher_logits = []\n",
    "batch_size = 100\n",
    "with torch.no_grad():\n",
    "    for i in range(0, n_sample-batch_size+1, batch_size):\n",
    "        teacher_logits.extend(teacher.forward(input_ids=input_ids[i:i+batch_size], \n",
    "                                              attention_mask=attention_mask[i:i+batch_size], \n",
    "                                              labels=labels[i:i+batch_size])['logits'].cpu().numpy())\n",
    "        \n",
    "teacher_logits = np.array(teacher_logits)\n",
    "y_pred = teacher_logits.argmax(axis=1)\n",
    "print(classification_report(y_train, y_pred))\n",
    "plt.hist(teacher_logits);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-HIdsqT4aB5",
    "outputId": "f5f79ec4-3550-4af8-ef15-466627533c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       496\n",
      "           1       0.85      0.83      0.84       504\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attention_mask = torch.tensor(test_ds['attention_mask'][:n_sample]).cuda()\n",
    "input_ids = torch.tensor(test_ds['input_ids'][:n_sample]).cuda()\n",
    "labels = torch.tensor(test_ds['label'][:n_sample]).cuda()\n",
    "\n",
    "test_teacher_logits = []\n",
    "batch_size = 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, n_sample-batch_size+1, batch_size):\n",
    "        test_teacher_logits.extend(teacher.forward(input_ids=input_ids[i:i+batch_size],\n",
    "                                              attention_mask=attention_mask[i:i+batch_size],\n",
    "                                              labels=labels[i:i+batch_size])['logits'].cpu().numpy())\n",
    "        \n",
    "test_teacher_logits = np.array(test_teacher_logits)\n",
    "y_pred = test_teacher_logits.argmax(axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiGCXgp8T4PL"
   },
   "source": [
    "- even beter than teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qw98r_Yn5GUM",
    "outputId": "f99de647-1107-45ab-8743-57ab8d7a8529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       496\n",
      "           1       0.84      0.86      0.85       504\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LinearRegression())\n",
    "student.fit(x_train, teacher_logits)\n",
    "\n",
    "y_pred = student.predict(x_test)\n",
    "print(classification_report(y_test, y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYU7zBIl5e_-"
   },
   "source": [
    "## More on KD\n",
    "- sub-class KD\n",
    "- self training with noisy student\n",
    "- Well Read Students\n",
    "- KD with TAs\n",
    "- classwise self KD\n",
    "- distillBERT "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "KD.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5770ed73217e40eb84247a3f1ecf34ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a787dbd6b8a4d4d89971eae9194af1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8700b639919f4dff9e08819ce087997d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8c307cd28fa04768b5d6b48e852e1dc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a02de1b5e59d4140b17f2ee681583207",
      "placeholder": "​",
      "style": "IPY_MODEL_6a787dbd6b8a4d4d89971eae9194af1b",
      "value": " 46.7M/46.7M [00:01&lt;00:00, 32.3MB/s]"
     }
    },
    "95999a0542da455a9043b5233dad6b34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5770ed73217e40eb84247a3f1ecf34ec",
      "max": 46747112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8700b639919f4dff9e08819ce087997d",
      "value": 46747112
     }
    },
    "9911d21048c94954a63b24b95e4b4ca8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a02de1b5e59d4140b17f2ee681583207": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ec4fc1ba4e471f82c20375d8efe464": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_95999a0542da455a9043b5233dad6b34",
       "IPY_MODEL_8c307cd28fa04768b5d6b48e852e1dc8"
      ],
      "layout": "IPY_MODEL_9911d21048c94954a63b24b95e4b4ca8"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
