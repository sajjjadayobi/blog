<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Introduction to Knowledge Distillation | Sajjad Ayoubiâ€™s Blog ðŸ˜‰</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Introduction to Knowledge Distillation" />
<meta name="author" content="Sajjad Ayoubi" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="whith two code examples" />
<meta property="og:description" content="whith two code examples" />
<link rel="canonical" href="https://sajjjadayobi.github.io/blog/implementation/2021/04/23/knowledge-distillation.html" />
<meta property="og:url" content="https://sajjjadayobi.github.io/blog/implementation/2021/04/23/knowledge-distillation.html" />
<meta property="og:site_name" content="Sajjad Ayoubiâ€™s Blog ðŸ˜‰" />
<meta property="og:image" content="https://sajjjadayobi.github.io/blog/images/kd.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-04-23T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://sajjjadayobi.github.io/blog/implementation/2021/04/23/knowledge-distillation.html","@type":"BlogPosting","headline":"Introduction to Knowledge Distillation","dateModified":"2021-04-23T00:00:00-05:00","datePublished":"2021-04-23T00:00:00-05:00","image":"https://sajjjadayobi.github.io/blog/images/kd.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://sajjjadayobi.github.io/blog/implementation/2021/04/23/knowledge-distillation.html"},"author":{"@type":"Person","name":"Sajjad Ayoubi"},"description":"whith two code examples","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sajjjadayobi.github.io/blog/feed.xml" title="Sajjad Ayoubi's Blog ðŸ˜‰" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Sajjad Ayoubi&#39;s Blog ðŸ˜‰</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Introduction to Knowledge Distillation</h1><p class="page-description">whith two code examples</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-04-23T00:00:00-05:00" itemprop="datePublished">
        Apr 23, 2021
      </time>â€¢ 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Sajjad Ayoubi</span></span>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#implementation">implementation</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/sajjjadayobi/blog/blob/master/_notebooks/2021-04-23-knowledge-distillation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#My-notes">My notes </a></li>
<li class="toc-entry toc-h2"><a href="#Vision-Example:-Mnist-Classification">Vision Example: Mnist Classification </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Alpha-&-Temp">Alpha &amp; Temp </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#NLP-Example:-IMDB-classification">NLP Example: IMDB classification </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Overfitted-Teacher">Overfitted Teacher </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#More-on-KD">More on KD </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-04-23-knowledge-distillation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>I found <a href="https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Neural-Networks--VmlldzoyMjkxODk">this</a> article great for details in knowledge distillation</li>
<li>
<p>Soft lables <a href="https://lh4.googleusercontent.com/ZoaRoo-dWpdIx7iCmbEICmFcOPJLuVC2fc_Pau6akiBbLG6ad-IczRXgKHhnMXDuCXJbmxRU8ucPUJXH18B-cLUTvWekxqQn3cJTaybv3RGK8_5U0lxL8ZOeT6UalyelYBFpxTiL">image</a></p>
</li>
<li>
<p>Reference:</p>
<ul>
<li><a href="https://arxiv.org/abs/1503.02531">Hinton et al. (2015)</a></li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="My-notes">
<a class="anchor" href="#My-notes" aria-hidden="true"><span class="octicon octicon-link"></span></a>My notes<a class="anchor-link" href="#My-notes"> </a>
</h2>
<ul>
<li>a high-quality Teacher is important</li>
<li>feature map level distillation<ul>
<li><code>DistilBERT</code></li>
</ul>
</li>
<li>the T and S can be anythings<ul>
<li>example: T is BERT, S is LSTM</li>
</ul>
</li>
<li>with <code>aug</code> it has more gain<ul>
<li>because augmented data has no hard label</li>
<li>with a huge T model we even don't need to have the same label <code>aug</code>
</li>
<li>it's kind of semi-supervised for S</li>
</ul>
</li>
<li>soft labeling is really mater in <code>LMs</code><ul>
<li>I have a cute [cat, dog, pet, ...] -&gt; dark knowledge</li>
<li>I have a cute [cat, tree, an, ...] -&gt; one hot</li>
</ul>
</li>
<li>
<code>KD</code> in Online learning<ul>
<li>you have a small model in Server</li>
<li>with a big Model for teaching with new data</li>
</ul>
</li>
<li>
<code>KD</code> help to regularizing <code>overfit</code> in neural networks<ul>
<li>Teacher learned generalization</li>
<li>but don't use it just for this purpose</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fri Apr 23 14:48:23 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vision-Example:-Mnist-Classification">
<a class="anchor" href="#Vision-Example:-Mnist-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Vision Example: Mnist Classification<a class="anchor-link" href="#Vision-Example:-Mnist-Classification"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span> <span class="o">,</span> <span class="nn">random</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">"float32"</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">"float32"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"same"</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">"relu"</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s2">"same"</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">"relu"</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"teacher"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">teacher</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">teacher</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'acc'</span><span class="p">])</span>

<span class="n">teacher</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "teacher"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 14, 14, 16)        160       
_________________________________________________________________
batch_normalization (BatchNo (None, 14, 14, 16)        64        
_________________________________________________________________
activation (Activation)      (None, 14, 14, 16)        0         
_________________________________________________________________
dropout (Dropout)            (None, 14, 14, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 7, 7, 32)          4640      
_________________________________________________________________
batch_normalization_1 (Batch (None, 7, 7, 32)          128       
_________________________________________________________________
activation_1 (Activation)    (None, 7, 7, 32)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                15690     
=================================================================
Total params: 20,682
Trainable params: 20,586
Non-trainable params: 96
_________________________________________________________________
Epoch 1/8
1875/1875 [==============================] - 38s 3ms/step - loss: 0.4718 - acc: 0.8510 - val_loss: 0.0876 - val_acc: 0.9749
Epoch 2/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.1137 - acc: 0.9645 - val_loss: 0.0631 - val_acc: 0.9796
Epoch 3/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0914 - acc: 0.9711 - val_loss: 0.0487 - val_acc: 0.9838
Epoch 4/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0799 - acc: 0.9753 - val_loss: 0.0472 - val_acc: 0.9844
Epoch 5/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0681 - acc: 0.9785 - val_loss: 0.0497 - val_acc: 0.9844
Epoch 6/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0624 - acc: 0.9801 - val_loss: 0.0416 - val_acc: 0.9863
Epoch 7/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0624 - acc: 0.9806 - val_loss: 0.0437 - val_acc: 0.9858
Epoch 8/8
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0557 - acc: 0.9824 - val_loss: 0.0379 - val_acc: 0.9870
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f4441a28290&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_student</span><span class="p">():</span>
    <span class="n">student</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
        <span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s2">"student"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">student</span>

<span class="n">student</span> <span class="o">=</span> <span class="n">create_student</span><span class="p">()</span>
<span class="n">student</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">student</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'acc'</span><span class="p">])</span>

<span class="n">student</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "student"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 14)                10990     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                150       
=================================================================
Total params: 11,140
Trainable params: 11,140
Non-trainable params: 0
_________________________________________________________________
Epoch 1/6
1875/1875 [==============================] - 4s 2ms/step - loss: 5.6094 - acc: 0.1999 - val_loss: 1.7388 - val_acc: 0.3541
Epoch 2/6
1875/1875 [==============================] - 3s 2ms/step - loss: 1.5936 - acc: 0.4178 - val_loss: 1.3059 - val_acc: 0.5489
Epoch 3/6
1875/1875 [==============================] - 3s 2ms/step - loss: 1.1982 - acc: 0.5602 - val_loss: 1.0485 - val_acc: 0.5982
Epoch 4/6
1875/1875 [==============================] - 3s 2ms/step - loss: 0.9959 - acc: 0.6132 - val_loss: 0.8854 - val_acc: 0.6836
Epoch 5/6
1875/1875 [==============================] - 4s 2ms/step - loss: 0.8133 - acc: 0.7029 - val_loss: 0.7248 - val_acc: 0.7487
Epoch 6/6
1875/1875 [==============================] - 3s 2ms/step - loss: 0.7247 - acc: 0.7540 - val_loss: 0.6509 - val_acc: 0.7917
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f43ee0f6b50&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>what is softmax temp</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">a</span><span class="o">/</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">a</span><span class="o">/</span><span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">a</span><span class="o">/</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># T is not a HyperParams</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tf.Tensor([0.97962921 0.01794253 0.00242826], shape=(3,), dtype=float64)
tf.Tensor([0.71483081 0.18842736 0.09674183], shape=(3,), dtype=float64)
tf.Tensor([0.57125779 0.25668267 0.17205954], shape=(3,), dtype=float64)
tf.Tensor([0.45062671 0.30206411 0.24730918], shape=(3,), dtype=float64)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DistillLeaner</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">teacher</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistillLeaner</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="n">teacher</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">student</span> <span class="o">=</span> <span class="n">student</span>

    <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">student_loss_fn</span><span class="p">,</span> <span class="n">distill_loss_fn</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistillLeaner</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">student_loss_fn</span> <span class="o">=</span> <span class="n">student_loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distill_loss_fn</span> <span class="o">=</span> <span class="n">distill_loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># Unpack data</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="c1"># Forward pass of teacher</span>
        <span class="n">teacher_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="c1"># Forward pass of student</span>
            <span class="n">student_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># CELoss on hard labels</span>
            <span class="n">student_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">student_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">student_logits</span><span class="p">)</span>
            <span class="c1"># distillation loss</span>
            <span class="n">distill_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distill_loss_fn</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">,</span> <span class="n">student_logits</span><span class="p">)</span>
            <span class="c1"># combine togather</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">student_loss</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">distill_loss</span>

        <span class="c1"># Compute gradients &amp; # Update weights</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

        <span class="c1"># Update the metrics configured in `compile()`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_metrics</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">student_logits</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>
        <span class="n">results</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"student_loss"</span><span class="p">:</span> <span class="n">student_loss</span><span class="p">,</span> <span class="s2">"distill_loss"</span><span class="p">:</span> <span class="n">distill_loss</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># Calculate the loss &amp; Update the metrics.</span>
        <span class="n">student_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">student_loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_metrics</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>
        <span class="n">results</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"student_loss"</span><span class="p">:</span> <span class="n">student_loss</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">distill_loss_on_probs</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">,</span> <span class="n">student_logits</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">KLDivergence</span><span class="p">(),</span> <span class="n">temp</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">teacher_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">teacher_logits</span> <span class="o">/</span> <span class="n">temp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">student_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">student_logits</span> <span class="o">/</span> <span class="n">temp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">teacher_probs</span><span class="p">,</span> <span class="n">student_logits</span><span class="p">)</span> <span class="o">*</span> <span class="n">temp</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distiller</span> <span class="o">=</span> <span class="n">DistillLeaner</span><span class="p">(</span><span class="n">student</span><span class="o">=</span><span class="n">create_student</span><span class="p">(),</span> <span class="n">teacher</span><span class="o">=</span><span class="n">teacher</span><span class="p">)</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">distiller</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'acc'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="c1"># alpcha depends on Teacher quality</span>
    <span class="n">student_loss_fn</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">distill_loss_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">distill_loss_on_probs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">KLDivergence</span><span class="p">(),</span> <span class="n">temp</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">distiller</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.3409 - student_loss: 2.2838 - distill_loss: 11.6732 - val_acc: 0.5336 - val_student_loss: 0.9119
Epoch 2/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.6224 - student_loss: 0.9106 - distill_loss: 6.0831 - val_acc: 0.8649 - val_student_loss: 0.7081
Epoch 3/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8674 - student_loss: 0.5287 - distill_loss: 2.5995 - val_acc: 0.8925 - val_student_loss: 0.0706
Epoch 4/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8882 - student_loss: 0.4622 - distill_loss: 2.2731 - val_acc: 0.8834 - val_student_loss: 0.0381
Epoch 5/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8914 - student_loss: 0.4507 - distill_loss: 2.2082 - val_acc: 0.8899 - val_student_loss: 0.1761
Epoch 6/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.8967 - student_loss: 0.4366 - distill_loss: 2.1420 - val_acc: 0.8942 - val_student_loss: 0.0060
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f43e66883d0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Alpha-&amp;-Temp">
<a class="anchor" href="#Alpha-&amp;-Temp" aria-hidden="true"><span class="octicon octicon-link"></span></a>Alpha &amp; Temp<a class="anchor-link" href="#Alpha-&amp;-Temp"> </a>
</h3>
<ul>
<li>good temp is range 1 to 5</li>
<li>train without smooting labels<ul>
<li>temp=1 regural softmax</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distiller</span> <span class="o">=</span> <span class="n">DistillLeaner</span><span class="p">(</span><span class="n">student</span><span class="o">=</span><span class="n">create_student</span><span class="p">(),</span> <span class="n">teacher</span><span class="o">=</span><span class="n">teacher</span><span class="p">)</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">distiller</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'acc'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="c1"># alpcha depends on Teacher quality</span>
    <span class="n">student_loss_fn</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">distill_loss_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">distill_loss_on_probs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">KLDivergence</span><span class="p">(),</span> <span class="n">temp</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
<span class="c1"># the effect of TEMP</span>
<span class="n">distiller</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.2859 - student_loss: 2.1936 - distill_loss: 1.7353 - val_acc: 0.5280 - val_student_loss: 0.9626
Epoch 2/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.5262 - student_loss: 1.2288 - distill_loss: 1.1484 - val_acc: 0.5785 - val_student_loss: 0.8914
Epoch 3/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.6132 - student_loss: 0.9515 - distill_loss: 0.8945 - val_acc: 0.7095 - val_student_loss: 0.4716
Epoch 4/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.7398 - student_loss: 0.7168 - distill_loss: 0.6630 - val_acc: 0.8145 - val_student_loss: 0.5897
Epoch 5/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8234 - student_loss: 0.5569 - distill_loss: 0.5128 - val_acc: 0.8512 - val_student_loss: 0.2171
Epoch 6/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8576 - student_loss: 0.4812 - distill_loss: 0.4433 - val_acc: 0.8633 - val_student_loss: 0.4472
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f43e636d790&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>train just with soft-teacher-labels</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distiller</span> <span class="o">=</span> <span class="n">DistillLeaner</span><span class="p">(</span><span class="n">student</span><span class="o">=</span><span class="n">create_student</span><span class="p">(),</span> <span class="n">teacher</span><span class="o">=</span><span class="n">teacher</span><span class="p">)</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">distiller</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'acc'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="c1"># hard labels are off</span>
    <span class="n">student_loss_fn</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">distill_loss_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">distill_loss_on_probs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">KLDivergence</span><span class="p">(),</span> <span class="n">temp</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">distiller</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.3481 - student_loss: 2.7879 - distill_loss: 11.4505 - val_acc: 0.7488 - val_student_loss: 0.9149
Epoch 2/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.7764 - student_loss: 0.6838 - distill_loss: 3.5558 - val_acc: 0.8822 - val_student_loss: 0.0873
Epoch 3/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8856 - student_loss: 0.4590 - distill_loss: 2.1813 - val_acc: 0.8943 - val_student_loss: 0.3185
Epoch 4/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8990 - student_loss: 0.4224 - distill_loss: 1.9759 - val_acc: 0.9022 - val_student_loss: 0.0621
Epoch 5/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.9040 - student_loss: 0.4136 - distill_loss: 1.9242 - val_acc: 0.9023 - val_student_loss: 0.3587
Epoch 6/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.9042 - student_loss: 0.4031 - distill_loss: 1.8885 - val_acc: 0.9033 - val_student_loss: 0.2638
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x7f43da269150&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Teacher Annealing Alpha from 0 to 1<ul>
<li>in earlier just look at the T then just Y</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TeacherAnnaling</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TeacherAnnaling</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
  
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+=</span> <span class="mi">1</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">distiller</span> <span class="o">=</span> <span class="n">DistillLeaner</span><span class="p">(</span><span class="n">student</span><span class="o">=</span><span class="n">create_student</span><span class="p">(),</span> <span class="n">teacher</span><span class="o">=</span><span class="n">teacher</span><span class="p">)</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">distiller</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'acc'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="c1"># alpcha depends on Teacher quality</span>
    <span class="n">student_loss_fn</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">distill_loss_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">distill_loss_on_probs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">KLDivergence</span><span class="p">(),</span> <span class="n">temp</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="c1"># temps is not a hyper</span>
<span class="p">)</span>
<span class="c1"># with CategoricalCrossentropy or MSE</span>
<span class="n">ta</span> <span class="o">=</span> <span class="n">TeacherAnnaling</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span> <span class="c1"># [from 0.0 to 1.0 step 0.2] </span>
<span class="n">distiller</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ta</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">distiller</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.4803 - student_loss: 3.1257 - distill_loss: 10.1510 - val_acc: 0.8081 - val_student_loss: 0.6410
Epoch 2/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8308 - student_loss: 0.6133 - distill_loss: 3.3149 - val_acc: 0.8937 - val_student_loss: 0.0219
Epoch 3/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.8961 - student_loss: 0.4369 - distill_loss: 2.0684 - val_acc: 0.9070 - val_student_loss: 0.0320
Epoch 4/6
1875/1875 [==============================] - 5s 2ms/step - acc: 0.9041 - student_loss: 0.3980 - distill_loss: 1.8594 - val_acc: 0.9054 - val_student_loss: 0.0431
Epoch 5/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.9108 - student_loss: 0.3774 - distill_loss: 1.7609 - val_acc: 0.9092 - val_student_loss: 0.0115
Epoch 6/6
1875/1875 [==============================] - 4s 2ms/step - acc: 0.9131 - student_loss: 0.3668 - distill_loss: 1.7028 - val_acc: 0.9109 - val_student_loss: 0.0230
0.9999999999999999
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="NLP-Example:-IMDB-classification">
<a class="anchor" href="#NLP-Example:-IMDB-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>NLP Example: IMDB classification<a class="anchor-link" href="#NLP-Example:-IMDB-classification"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install -q transformers
<span class="o">!</span>pip install -q datasets
<span class="o">!</span>pip install -q sentencepiece
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 9.0MB/s 
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 49.9MB/s 
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 52.5MB/s 
  Building wheel for sacremoses (setup.py) ... done
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 8.3MB/s 
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 16.6MB/s 
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 17.6MB/s 
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 8.2MB/s 
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AlbertForSequenceClassification</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s1">'textattack/albert-base-v2-imdb'</span>
<span class="n">max_length</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">3e-5</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">'imdb'</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'test'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">toknize_with_padding</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">'text'</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span> <span class="c1"># bad model </span>
<span class="c1"># prepare datasets</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">toknize_with_padding</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">toknize_with_padding</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[:</span><span class="n">n_sample</span><span class="p">][</span><span class="s1">'text'</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[:</span><span class="n">n_sample</span><span class="p">][</span><span class="s1">'label'</span><span class="p">])</span>

<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[:</span><span class="n">n_sample</span><span class="p">][</span><span class="s1">'text'</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[:</span><span class="n">n_sample</span><span class="p">][</span><span class="s1">'label'</span><span class="p">])</span>

<span class="n">student</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">LogisticRegression</span><span class="p">())</span> <span class="c1"># CountVectorizer</span>
<span class="n">student</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'model trained'</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">student</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>model trained
              precision    recall  f1-score   support

           0       0.86      0.69      0.77       496
           1       0.75      0.89      0.81       504

    accuracy                           0.79      1000
   macro avg       0.81      0.79      0.79      1000
weighted avg       0.80      0.79      0.79      1000

CPU times: user 2.28 s, sys: 983 ms, total: 3.27 s
Wall time: 2.29 s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher</span> <span class="o">=</span> <span class="n">AlbertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">teacher</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'model loaded'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
model loaded
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">'label'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">test_teacher_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">-</span><span class="n">batch_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">test_teacher_logits</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">teacher</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> 
                                              <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> 
                                              <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">])[</span><span class="s1">'logits'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
<span class="n">test_teacher_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_teacher_logits</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">test_teacher_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.87      0.82      0.85       496
           1       0.83      0.88      0.86       504

    accuracy                           0.85      1000
   macro avg       0.85      0.85      0.85      1000
weighted avg       0.85      0.85      0.85      1000

</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">'label'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">teacher_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">-</span><span class="n">batch_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">teacher_logits</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">teacher</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> 
                                              <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> 
                                              <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">])[</span><span class="s1">'logits'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
<span class="n">teacher_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">teacher_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.90      0.85      0.87       472
           1       0.87      0.91      0.89       528

    accuracy                           0.88      1000
   macro avg       0.89      0.88      0.88      1000
weighted avg       0.88      0.88      0.88      1000

</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>using logist we don't need temp</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">student</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">teacher_logits</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">student</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.86      0.76      0.81       496
           1       0.79      0.88      0.83       504

    accuracy                           0.82      1000
   macro avg       0.83      0.82      0.82      1000
weighted avg       0.83      0.82      0.82      1000

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Overfitted-Teacher">
<a class="anchor" href="#Overfitted-Teacher" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overfitted Teacher<a class="anchor-link" href="#Overfitted-Teacher"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">"result"</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s1">'epoch'</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">999999</span><span class="p">,</span> <span class="c1"># we don't need saving </span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">8e-6</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">teacher</span> <span class="o">=</span> <span class="n">AlbertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">teacher</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)))</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">teacher</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'End'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
        </style>
      
      <progress value="126" max="126" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [126/126 00:20, Epoch 2/2]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Runtime</th>
      <th>Samples Per Second</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>No log</td>
      <td>0.139151</td>
      <td>2.438800</td>
      <td>410.044000</td>
    </tr>
    <tr>
      <td>2</td>
      <td>No log</td>
      <td>0.090243</td>
      <td>2.437100</td>
      <td>410.324000</td>
    </tr>
  </tbody>
</table>
<p>
&lt;/div&gt;

&lt;/div&gt;

</p>
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>End
</pre>
</div>
</div>

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">'label'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">teacher_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">-</span><span class="n">batch_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">teacher_logits</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">teacher</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> 
                                              <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> 
                                              <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">])[</span><span class="s1">'logits'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
<span class="n">teacher_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">teacher_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.98      0.96      0.97       472
           1       0.97      0.98      0.97       528

    accuracy                           0.97      1000
   macro avg       0.97      0.97      0.97      1000
weighted avg       0.97      0.97      0.97      1000

</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s1">'label'</span><span class="p">][:</span><span class="n">n_sample</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">test_teacher_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">-</span><span class="n">batch_size</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">test_teacher_logits</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">teacher</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span>
                                              <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span>
                                              <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">])[</span><span class="s1">'logits'</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
<span class="n">test_teacher_logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_teacher_logits</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">test_teacher_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.83      0.85      0.84       496
           1       0.85      0.83      0.84       504

    accuracy                           0.84      1000
   macro avg       0.84      0.84      0.84      1000
weighted avg       0.84      0.84      0.84      1000

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>even beter than teacher</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">student</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">student</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">teacher_logits</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">student</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.85      0.84      0.84       496
           1       0.84      0.86      0.85       504

    accuracy                           0.85      1000
   macro avg       0.85      0.85      0.85      1000
weighted avg       0.85      0.85      0.85      1000

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="More-on-KD">
<a class="anchor" href="#More-on-KD" aria-hidden="true"><span class="octicon octicon-link"></span></a>More on KD<a class="anchor-link" href="#More-on-KD"> </a>
</h2>
<ul>
<li>sub-class KD</li>
<li>self training with noisy student</li>
<li>Well Read Students</li>
<li>KD with TAs</li>
<li>classwise self KD</li>
<li>distillBERT </li>
</ul>

</div>
</div>
</div>
&lt;/div&gt;
 

<script type="application/vnd.jupyter.widget-state+json">
{"5770ed73217e40eb84247a3f1ecf34ec": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6a787dbd6b8a4d4d89971eae9194af1b": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "8700b639919f4dff9e08819ce087997d": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "8c307cd28fa04768b5d6b48e852e1dc8": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_a02de1b5e59d4140b17f2ee681583207", "placeholder": "\u200b", "style": "IPY_MODEL_6a787dbd6b8a4d4d89971eae9194af1b", "value": " 46.7M/46.7M [00:01&lt;00:00, 32.3MB/s]"}}, "95999a0542da455a9043b5233dad6b34": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_5770ed73217e40eb84247a3f1ecf34ec", "max": 46747112, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_8700b639919f4dff9e08819ce087997d", "value": 46747112}}, "9911d21048c94954a63b24b95e4b4ca8": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a02de1b5e59d4140b17f2ee681583207": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a6ec4fc1ba4e471f82c20375d8efe464": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_95999a0542da455a9043b5233dad6b34", "IPY_MODEL_8c307cd28fa04768b5d6b48e852e1dc8"], "layout": "IPY_MODEL_9911d21048c94954a63b24b95e4b4ca8"}}}
</script>

</div>
</div>
</div>
</div>
</div>
</div>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="sajjjadayobi/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/implementation/2021/04/23/knowledge-distillation.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Sajjad Ayoubi</li>
          <li><a class="u-email" href="mailto:sadeveloper360@gmail.com">sadeveloper360@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sajjjadayobi" title="sajjjadayobi"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/ayoubi_sajjad" title="ayoubi_sajjad"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
